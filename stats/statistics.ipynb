{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nnLB_4xNZZCi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25884,
     "status": "ok",
     "timestamp": 1684560586669,
     "user": {
      "displayName": "Karan Yadav",
      "userId": "16084954556777141985"
     },
     "user_tz": -330
    },
    "id": "nnLB_4xNZZCi",
    "outputId": "43b96b46-e49a-41e1-abb9-a4f86449818c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "kiBIH0j4E2Ot",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5524,
     "status": "ok",
     "timestamp": 1684560592182,
     "user": {
      "displayName": "Karan Yadav",
      "userId": "16084954556777141985"
     },
     "user_tz": -330
    },
    "id": "kiBIH0j4E2Ot",
    "outputId": "40403369-d024-4b12-e95e-8b03f0b58055"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pyconll\n",
      "  Downloading pyconll-3.1.0-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: pyconll\n",
      "Successfully installed pyconll-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyconll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0-gJCE1-DqBq",
   "metadata": {
    "id": "0-gJCE1-DqBq"
   },
   "outputs": [],
   "source": [
    "# !pip install stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a959d2",
   "metadata": {
    "id": "06a959d2"
   },
   "outputs": [],
   "source": [
    "## Number of Sentences, words in the file\n",
    "\n",
    "\n",
    "import os\n",
    "import pyconll\n",
    "import csv\n",
    "\n",
    "\n",
    "def statistics(filepath):\n",
    "  '''This function calculates the statistics of the corpus developed over phases.\n",
    "      File path given to function has following file structure to access output CoNLL files:\n",
    "      Filepath >> \n",
    "          Phases >> \n",
    "            Output files/temp_files/csv input files >>\n",
    "              output CoNLL files \n",
    "  '''\n",
    "\n",
    "\n",
    "\n",
    "  dirs = sorted(os.listdir(filepath))       # Creating sorted list of directories from given path\n",
    "\n",
    "  result_list = []                          # Initializing list to add all statistics\n",
    "\n",
    "  Total_sent = 0                      # Initializing variable to store total number of sentences in corpus\n",
    "  Total_words = 0                     # Initializing variable to store total number of tokens in corpus\n",
    "  Total_speakers = 0                  # Initializing variable to store total number of speakers in corpus\n",
    "  Total_repair = 0                    # Initializing variable to store total number of repairs in corpus\n",
    "  Total_disfluency =0                 # Initializing variable to store total number of disfluencies in corpus\n",
    "  Total_hesitation = 0\n",
    "  Total_codeswitch =0                 # Initializing variable to store total number of codeswitches in corpus\n",
    "  Total_other_tags =0                 # Initializing variable to store total number of tags except repair, disfluencies and codeswitches in corpus\n",
    "  Total_words_without_tags = 0        # Initializing variable to store total number of tokens except tagged in corpus\n",
    "  Total_words_tags = 0                # Initializing variable to store total number of tagged tokens in corpus\n",
    "\n",
    "  Total_time=0                      # Initializing variable to calculate total time of corpus dialect\n",
    "\n",
    "  title = ['Phase','Filename','Duration','No.of_Speakers','No.of_Sentences','No.of_Tokens(all)','No.of_Repair',\n",
    "           'No.of_Disfluency', 'Hesitation','No.of_Code-switching','No.of_OtherTags','No.of_Tokens(w/o chunks&OtherTags)']\n",
    "\n",
    "  result_list.append(title)           # Adding heading to csv file\n",
    "\n",
    "  # for every file in the directory\n",
    "  for file in dirs:\n",
    "      # print(file)\n",
    "      if not os.path.isfile((filepath+str(file))):         # Ignoring the files and only considering folders in given path  \n",
    "\n",
    "        phase_dir = sorted(os.listdir(filepath+str(file)))\n",
    "        Phase = file[-1]                                  # Considering the phase of output files\n",
    "\n",
    "        for phases in phase_dir:                           \n",
    "          # print(phases)\n",
    "          if not os.path.isfile((filepath+str(file)+\"/\"+str(phases))):\n",
    "            outputfiles_dir = sorted(os.listdir(filepath+str(file)+\"/\"+str(phases)))   # Accessing output files folder in each phase\n",
    "\n",
    "            for output_file in outputfiles_dir:\n",
    "              \n",
    "              filename = filepath+str(file)+\"/\"+str(phases)+\"/\"+str(output_file)    # Looping over each output file in output files folder\n",
    "\n",
    "              if filename.endswith(\"_output.txt\"):\n",
    "\n",
    "                  filename_in = filename\n",
    "    \n",
    "                  file1 = pyconll.load_from_file(filename_in)        # Loading CoNLL output file using pyconll module\n",
    "\n",
    "\n",
    "                  count_sent = 0             #Initializing variable for sentences in each output file\n",
    "                  count_word = 0             #Initializing variable for tokens in each output file\n",
    "                  count_tags = 0             #Initializing variable for tagged tokens in each output file\n",
    "                  list_form= [\"[laughter]\", \"[noise]\", \"[incomprehensible]\", \"[pause]\",\"[aside]\"]   # List of other tags than repair, disfluencies and codeswitch\n",
    "                  list_form_count=0          #Initializing variable for tags in above list in each output file\n",
    "                  count_repair = 0\n",
    "                  count_disfluency = 0\n",
    "                  count_hesitation = 0\n",
    "                  count_codeswitch = 0\n",
    "                  count_quote = 0\n",
    "                  \n",
    "                  # list_misc_count=0\n",
    "                  misc_keys = []\n",
    "\n",
    "                  for sentence in file1:\n",
    "                      count_sent+=1             # Counting number of sentences in each output file\n",
    "                      \n",
    "                      for token in sentence:           \n",
    "                          \n",
    "                          if \"_\" in token.form:                           \n",
    "                              chunk_split=token.form.split(\"_\")           #Splitting token if it is chunk\n",
    "          #                     print(chunk_split) \n",
    "                              count_word+=len(chunk_split)                #Counting words in the chunk \n",
    "                          else:\n",
    "                              count_word+=1\n",
    "                              \n",
    "\n",
    "                          if token.form in list_form:\n",
    "          #                     print(token.form)\n",
    "                              list_form_count+=1           # Maintaining count of tags mentioned in above list\n",
    "\n",
    "                          \n",
    "                          for i in token.misc.keys():\n",
    "                              if i=='Repair':\n",
    "                                  count_repair+=1         # Counting repairs in output file\n",
    "                              if i =='Disfluency':\n",
    "                                  count_disfluency+=1     # Counting disfluencies in output file\n",
    "                              \n",
    "                              if i =='Hesitation':\n",
    "                                  count_hesitation+=1\n",
    "\n",
    "                              if i =='CodeSwitch':\n",
    "                                  count_codeswitch+=1     # Counting codeswitch in output file  \n",
    "                                  \n",
    "                              if i =='Quote':\n",
    "                                  count_quote+=1          # Counting quotes in output file\n",
    "      \n",
    "                 \n",
    "                  total_chunks = count_repair + count_disfluency + count_codeswitch + count_quote\n",
    "                  #     print(\"total_chunks: \", total_chunks)\n",
    "\n",
    "                  tokens_without_tags = count_word - total_chunks - list_form_count   # Counting tokens without tags\n",
    "                  \n",
    "                  \n",
    "                  end_time=0\n",
    "                  speakers= []\n",
    "                  \n",
    "                  for sentence in file1:\n",
    "                      speakers.append(sentence.meta_value('speaker_id'))\n",
    "                      \n",
    "                      if(sentence.meta_value('sent_id')==str(count_sent)):       # Storing end time of last sentence of output file to get total duration of file\n",
    "                          end_time = (sentence.meta_value('end_time'))           \n",
    "                          t = end_time.split(':')\n",
    "                          total_min =int(t[1])\n",
    "                      \n",
    "                          if(float(t[2])>30.0):\n",
    "                              total_min+=1\n",
    "          \n",
    "                  print(filename, set(speakers))                    \n",
    "                  speakers = len(list(set(speakers)))          # Counting number of speakers in each output file\n",
    "                  \n",
    "\n",
    "                  Total_sent += count_sent          \n",
    "                  Total_speakers += speakers\n",
    "                  Total_words+= count_word\n",
    "                  Total_repair +=count_repair\n",
    "                  Total_disfluency +=count_disfluency\n",
    "                  Total_hesitation +=count_hesitation\n",
    "                  Total_other_tags +=list_form_count\n",
    "                  Total_words_without_tags +=tokens_without_tags\n",
    "                  Total_words_tags += count_word-list_form_count\n",
    "                  Total_time +=total_min\n",
    "\n",
    "                  \n",
    "\n",
    "                  # print(tokens_without_tags)\n",
    "                      \n",
    "                  result_list.append([Phase,output_file.replace(\"_output\", \"\"),end_time,speakers,\n",
    "                                      count_sent,count_word,count_repair,count_disfluency,count_hesitation,\n",
    "                                      count_codeswitch, list_form_count,tokens_without_tags])         # Appending stats of each output file\n",
    "                  # import pdb;pdb.set_trace()\n",
    "  result_list.append([\"\",\"Total Stats\",str(Total_time)+\" mins\",Total_speakers,Total_sent, Total_words,Total_repair,Total_disfluency,Total_hesitation,\n",
    "                    Total_codeswitch,Total_other_tags,Total_words_without_tags])        \n",
    "           \n",
    "\n",
    "\n",
    "  try:\n",
    "      file_out = os.path.join(filepath, \"Stat_20230516.csv\")                           # Creating Stat.csv file in given filepath \n",
    "      with open(file_out, \"w\",encoding=\"utf-8\", newline='',) as csvfile:  \n",
    "          # creating a csv writer object\n",
    "          csvwriter = csv.writer(csvfile, delimiter = ',')               \n",
    "          csvwriter.writerows(result_list)                                   # Writing result list in csvfile\n",
    "\n",
    "  except OSError as error:                          # Ensuring stat.csv file be over written every time script runs\n",
    "      pass\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d71cc8b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4504,
     "status": "ok",
     "timestamp": 1684259251803,
     "user": {
      "displayName": "Karan Yadav",
      "userId": "16084954556777141985"
     },
     "user_tz": -330
    },
    "id": "1d71cc8b",
    "outputId": "a77dfe9b-0535-4f8b-8d9d-387a5b62e827"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/HD Corpus/Files/Phase 1/Output_files/hi_1385_output.txt {'Sp2', 'Sp1'}\n",
      "3022\n",
      "/content/drive/MyDrive/HD Corpus/Files/Phase 1/Output_files/hi_4370_output.txt {'Sp2', 'Sp1', 'Sp3'}\n",
      "3111\n",
      "/content/drive/MyDrive/HD Corpus/Files/Phase 1/Output_files/hi_6322_output.txt {'Sp2', 'Sp1', 'Sp3'}\n",
      "3843\n",
      "/content/drive/MyDrive/HD Corpus/Files/Phase 1/Output_files/hi_6435_output.txt {'Sp2', 'Sp1'}\n",
      "5495\n",
      "/content/drive/MyDrive/HD Corpus/Files/Phase 1/Output_files/hi_6441_output.txt {'Sp2', 'Sp1'}\n",
      "3560\n",
      "/content/drive/MyDrive/HD Corpus/Files/Phase 1/Output_files/hi_6523_output.txt {'Sp2', 'Sp1'}\n",
      "7516\n",
      "/content/drive/MyDrive/HD Corpus/Files/Phase 1/Output_files/hi_6579_output.txt {'Sp2', 'Sp1'}\n",
      "3306\n",
      "/content/drive/MyDrive/HD Corpus/Files/Phase 1/Output_files/hi_6585_output.txt {'Sp2', 'Sp1'}\n",
      "5340\n",
      "/content/drive/MyDrive/HD Corpus/Files/Phase 2/Output_files/hi_1580_output.txt {'Sp2', 'Sp1'}\n",
      "6911\n",
      "/content/drive/MyDrive/HD Corpus/Files/Phase 2/Output_files/hi_2142_output.txt {'Sp2', 'Sp1'}\n",
      "7705\n",
      "/content/drive/MyDrive/HD Corpus/Files/Phase 2/Output_files/hi_2148_output.txt {'Sp2', 'Sp1'}\n",
      "6274\n",
      "/content/drive/MyDrive/HD Corpus/Files/Phase 2/Output_files/hi_2156_output.txt {'Sp2', 'Sp1'}\n",
      "6433\n",
      "/content/drive/MyDrive/HD Corpus/Files/Phase 2/Output_files/hi_4115_output.txt {'Sp2', 'Sp1'}\n",
      "6500\n",
      "/content/drive/MyDrive/HD Corpus/Files/Phase 2/Output_files/hi_4214_output.txt {'Sp2', 'Sp1'}\n",
      "6344\n",
      "/content/drive/MyDrive/HD Corpus/Files/Phase 2/Output_files/hi_4284_output.txt {'Sp2', 'Sp1', 'Sp3'}\n",
      "6753\n",
      "/content/drive/MyDrive/HD Corpus/Files/Phase 2/Output_files/hi_4360_output.txt {'Sp2', 'Sp1'}\n",
      "7124\n",
      "/content/drive/MyDrive/HD Corpus/Files/Phase 2/Output_files/hi_4649_output.txt {'Sp2', 'Sp1', 'Sp3'}\n",
      "6196\n",
      "/content/drive/MyDrive/HD Corpus/Files/Phase 2/Output_files/hi_4770_output.txt {'Sp2', 'Sp1', 'Sp3'}\n",
      "8031\n",
      "/content/drive/MyDrive/HD Corpus/Files/Phase 2/Output_files/hi_6256_output.txt {'Sp2', 'Sp1', 'Sp3'}\n",
      "6975\n",
      "/content/drive/MyDrive/HD Corpus/Files/Phase 2/Output_files/hi_6270_output.txt {'Sp2', 'Sp1'}\n",
      "7910\n",
      "/content/drive/MyDrive/HD Corpus/Files/Phase 2/Output_files/hi_6289_output.txt {'Sp2', 'Sp1', 'Sp3'}\n",
      "5375\n",
      "/content/drive/MyDrive/HD Corpus/Files/Phase 2/Output_files/hi_6300_output.txt {'Sp2', 'Sp1'}\n",
      "8046\n",
      "/content/drive/MyDrive/HD Corpus/Files/Phase 2/Output_files/hi_6400_output.txt {'Sp2', 'Sp1', 'Sp3'}\n",
      "5705\n",
      "/content/drive/MyDrive/HD Corpus/Files/Phase 2/Output_files/hi_6412_output.txt {'Sp2', 'Sp1'}\n",
      "6698\n"
     ]
    }
   ],
   "source": [
    "path = \"/content/drive/MyDrive/HD Corpus/Files/\"\n",
    "statistics(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lq8ox2lvLeTj",
   "metadata": {
    "id": "lq8ox2lvLeTj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
