{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evBy4THFZ0kn",
   "metadata": {
    "id": "evBy4THFZ0kn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "VMJgT7_-Z93f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34044,
     "status": "ok",
     "timestamp": 1652088282613,
     "user": {
      "displayName": "Karan Yadav",
      "userId": "16084954556777141985"
     },
     "user_tz": -330
    },
    "id": "VMJgT7_-Z93f",
    "outputId": "b296c426-455c-4af6-e8f3-33cf92be7573"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "kiBIH0j4E2Ot",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3907,
     "status": "ok",
     "timestamp": 1652088286483,
     "user": {
      "displayName": "Karan Yadav",
      "userId": "16084954556777141985"
     },
     "user_tz": -330
    },
    "id": "kiBIH0j4E2Ot",
    "outputId": "ae82ef9b-de30-4263-dc14-37ff7e293390"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyconll\n",
      "  Downloading pyconll-3.1.0-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: pyconll\n",
      "Successfully installed pyconll-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyconll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0-gJCE1-DqBq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14765,
     "status": "ok",
     "timestamp": 1652088307268,
     "user": {
      "displayName": "Karan Yadav",
      "userId": "16084954556777141985"
     },
     "user_tz": -330
    },
    "id": "0-gJCE1-DqBq",
    "outputId": "55a4dc8c-2f42-4cc8-ac8a-a774ce4dbd7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stanza\n",
      "  Downloading stanza-1.4.0-py3-none-any.whl (574 kB)\n",
      "\u001b[K     |████████████████████████████████| 574 kB 4.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanza) (4.64.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from stanza) (1.15.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza) (3.17.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanza) (1.21.6)\n",
      "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza) (1.11.0+cu113)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 45.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza) (2.23.0)\n",
      "Collecting emoji\n",
      "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
      "\u001b[K     |████████████████████████████████| 175 kB 49.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->stanza) (4.2.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2.10)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[K     |████████████████████████████████| 596 kB 43.9 MB/s \n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 4.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (3.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (2019.12.20)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (21.3)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers->stanza) (4.11.3)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001b[K     |████████████████████████████████| 880 kB 50.4 MB/s \n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.6 MB 17.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers->stanza) (3.0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers->stanza) (3.8.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->stanza) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->stanza) (1.1.0)\n",
      "Building wheels for collected packages: emoji, sacremoses\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=9de9a8e69b4cdbadab5bfd59966651c00625fbd7518b8312ef2e5fc9dcdfed02\n",
      "  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=3fe6f5c1234cd53cc30a88e0fb676d6670438b827f4f8cc4d157f94ec3bf3361\n",
      "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
      "Successfully built emoji sacremoses\n",
      "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers, emoji, stanza\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed emoji-1.7.0 huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.53 stanza-1.4.0 tokenizers-0.12.1 transformers-4.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95c8827b",
   "metadata": {
    "executionInfo": {
     "elapsed": 775,
     "status": "ok",
     "timestamp": 1652090621770,
     "user": {
      "displayName": "Karan Yadav",
      "userId": "16084954556777141985"
     },
     "user_tz": -330
    },
    "id": "95c8827b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def checks(file_path):\n",
    "    '''This script checks the CSV file for the following errors:\n",
    "            # check for pipe symbol instead of hindi purnaviram symbol and undo if found \n",
    "            # pairing of annotation tags\n",
    "            - even number of instances in each utterance \n",
    "            - if not, print the error with filename, begin_time, utterance\n",
    "            # the overlap tag should be equal in number for Sp1 and Sp2 - print the no. of # for Sp1 and Sp2\n",
    "            '''\n",
    "    \n",
    "    dirs = os.listdir(file_path)\n",
    " \n",
    "    # for every file in the directory\n",
    "    for phase in dirs:\n",
    "      if not os.path.isfile((file_path+str(phase))):                                      # Looping over number of phase folders in given directory\n",
    "        phase_dir = sorted(os.listdir(file_path+str(phase)))\n",
    "      \n",
    "      for file in phase_dir:\n",
    "        if os.path.isfile((file_path+str(phase)+\"/\"+str(file))):                                # Looping over input csv files in each of the phase folders    \n",
    "          filename = file_path+str(phase)+\"/\"+str(file)\n",
    "        # print(filename)\n",
    "        \n",
    "          if filename.endswith(\"_0.csv\"):\n",
    "              filename_in = filename\n",
    "\n",
    "              fields = []\n",
    "              rows = []\n",
    "              column_value = \"\"             #variable for the string in the transcription column\n",
    "              data_value= \"\"                #variable for the string in the transcription column as it will appear in the output file\n",
    "              speaker_value = \"\"            #variable for the string value of Speaker1 or Speaker2\n",
    "              result_list = []\n",
    "\n",
    "              count_overlap_sp1 = 0\n",
    "              count_overlap_sp2 = 0\n",
    "\n",
    "              with open(filename_in, 'r', encoding=\"utf-8\") as csvfile:\n",
    "                  csvreader = csv.reader(csvfile)\n",
    "                  reader = csv.DictReader(csvfile, delimiter=\",\")\n",
    "                  #print (filename_in)\n",
    "\n",
    "                  for row in reader:\n",
    "\n",
    "                      begin_time = row[\"Begin Time - hh:mm:ss.ms\"]\n",
    "                      end_time = row[\"End Time - hh:mm:ss.ms\"]\n",
    "                      duration = row[\"Duration - hh:mm:ss.ms\"]\n",
    "                      speaker_1 = row[\"Channel1\"]\n",
    "                      speaker_2 = row[\"Channel2\"]\n",
    "\n",
    "\n",
    "                      # the last above line assigns str in \"data\" column to variable data_value. \n",
    "                      # Also replaces a double white space with a single white space \n",
    "                      # Replaces pipe symbol with hindi purnaviram symbol\n",
    "                      if speaker_1 !=\"\":\n",
    "                          data_value=speaker_1   #+str(\" ।\");     #Adding Purnaviram to see how pipeline works when \n",
    "                      else:                                  #transcription already have it   \n",
    "                          data_value=speaker_2   #+str(\" ।\");\n",
    "\n",
    "                      data_value = str(data_value).replace(\"  \",\" \").replace(\"|\",\"।\").replace(\"/\",\"\\\\\")\n",
    "                      #count the number of \\d in the utterance and print (filename+begin_time_utterance) if odd number of occurances\n",
    "                      count_d = int(data_value.count(r\"\\d\"))\n",
    "                      if (count_d % 2) != 0:   \n",
    "                          print (\"ERROR FOR d: \" + filename_in[-13:-6] + \" \" + begin_time + \" \" + data_value)\n",
    "\n",
    "                      #count the number of \\r in the utterance and print (filename+begin_time_utterance) if odd number of occurances\n",
    "                      count_r = int(data_value.count(r\"\\r\"))\n",
    "                      if (count_r % 2) != 0:   \n",
    "                          print (\"ERROR FOR r: \" + filename_in[-13:-6] + \" \" + begin_time + \" \" + data_value)\n",
    "\n",
    "                      #count the number of \\h in the utterance and print (filename+begin_time_utterance) if odd number of occurances\n",
    "                      count_h = int(data_value.count(r\"\\h\"))\n",
    "                      if (count_h % 2) != 0:   \n",
    "                          print (\"ERROR FOR h: \" + filename_in[-13:-6] + \" \" + begin_time + \" \" + data_value)\n",
    "\n",
    "                      #count the number of \\exp in the utterance and print (filename+begin_time_utterance) if odd number of occurances\n",
    "                      count_exp = int(data_value.count(r\"\\exp\"))\n",
    "                      if (count_exp % 2) != 0:   \n",
    "                          print (\"ERROR FOR exp: \" + filename_in[-13:-6] + \" \" + begin_time + \" \" + data_value)\n",
    "\n",
    "                      #count the number of \\q in the utterance and print (filename+begin_time_utterance) if odd number of occurances\n",
    "                      count_q = int(data_value.count(r\"\\q\"))\n",
    "                      if (count_q % 2) != 0:   \n",
    "                          print (\"ERROR FOR q: \" + filename_in[-13:-6] + \" \" + begin_time + \" \" + data_value)\n",
    "\n",
    "                      #count the number of \\c in the utterance and print (filename+begin_time_utterance) if odd number of occurances\n",
    "                      count_c = int(data_value.count(r\"\\c\"))\n",
    "                      if (count_c % 2) != 0:   \n",
    "                          print (\"ERROR FOR c: \" + filename_in[-13:-6] + \" \" + begin_time + \" \" + data_value)\n",
    "\n",
    "                      #count the number of # in the utterance and print (filename+begin_time_utterance) if odd number of occurances\n",
    "                      count_overlap = int(data_value.count(r\"#\"))\n",
    "                      if (count_overlap % 2) != 0:   \n",
    "                          print (\"ERROR FOR overlap: \" + filename_in[-13:-6] + \" \" + begin_time + \" \" + data_value)\n",
    "\n",
    "                      #to check overlaps - additional check - for the 2 speakers, the total number of overlap tags should be the same\n",
    "                      if speaker_1 != \"\":\n",
    "                          count_overlap_sp1 = count_overlap_sp1 + count_overlap\n",
    "                      if speaker_2 != \"\":\n",
    "                          count_overlap_sp2 = count_overlap_sp2 + count_overlap\n",
    "\n",
    "                      if speaker_1 !=\"\":\n",
    "                          speaker_1=data_value;\n",
    "                      else:\n",
    "                          speaker_2=data_value;\n",
    "                          \n",
    "                          \n",
    "                      speaker_1 = str(speaker_1).replace(\"  \",\" \").replace(\"|\",\"।\")\n",
    "                      speaker_2 = str(speaker_2).replace(\"  \",\" \").replace(\"|\",\"।\")\n",
    "\n",
    "                      result_list.append([begin_time, end_time, duration, speaker_1, speaker_2])\n",
    "                      #print(result_list)\n",
    "\n",
    "              #the following prints for each file, the total number of overlap tags for Sp1 and Sp2 \n",
    "              \n",
    "              print (str(filename_in[-13:-6]) + \" Sp1 overlap count is \" + str(int(count_overlap_sp1)))\n",
    "              print (str(filename_in[-13:-6]) + \" Sp2 overlap count is \" + str(int(count_overlap_sp2)))\n",
    "\n",
    "                \n",
    "              \n",
    "              \n",
    "              #Create a New folder to store output of intermediatory steps\n",
    "              directory= \"temp_files\" \n",
    "              new_path=os.path.join(path+str(phase)+\"/\",directory)\n",
    "              # print(new_path)\n",
    "              try:\n",
    "                  os.makedirs(new_path,exist_ok=True)\n",
    "              except OSError as error:\n",
    "                  pass\n",
    "\n",
    "\n",
    "              new_filename = file.replace(\"_0.csv\", \"_0_checks.txt\")\n",
    "              filename_out2 = os.path.join(new_path,new_filename)\n",
    "              # print(filename_out2)\n",
    "\n",
    "\n",
    "              \n",
    "                  \n",
    "              with open(filename_out2, 'w',encoding=\"utf-8\", newline='') as csvfile:\n",
    "                  # creating a csv writer object\n",
    "                  csvwriter = csv.writer(csvfile)\n",
    "                  # writing the fields\n",
    "                  fields = [\"Begin Time - hh:mm:ss.ms\",\"End Time - hh:mm:ss.ms\",\"Duration - hh:mm:ss.ms\", 'Channel1','Channel2']\n",
    "                  csvwriter.writerow(fields)\n",
    "                  csvwriter.writerows(result_list)\n",
    "\n",
    "                  \n",
    "                  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "t8NNSaiQWTiJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 814,
     "status": "ok",
     "timestamp": 1652090624714,
     "user": {
      "displayName": "Karan Yadav",
      "userId": "16084954556777141985"
     },
     "user_tz": -330
    },
    "id": "t8NNSaiQWTiJ",
    "outputId": "d0fc995d-20c9-4339-c5b8-75201a23ab56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi_1385 Sp1 overlap count is 176\n",
      "hi_1385 Sp2 overlap count is 176\n",
      "hi_4370 Sp1 overlap count is 134\n",
      "hi_4370 Sp2 overlap count is 134\n",
      "hi_6322 Sp1 overlap count is 100\n",
      "hi_6322 Sp2 overlap count is 100\n",
      "hi_6435 Sp1 overlap count is 188\n",
      "hi_6435 Sp2 overlap count is 188\n",
      "hi_6441 Sp1 overlap count is 142\n",
      "hi_6441 Sp2 overlap count is 142\n",
      "hi_6523 Sp1 overlap count is 392\n",
      "hi_6523 Sp2 overlap count is 392\n",
      "hi_6579 Sp1 overlap count is 204\n",
      "hi_6579 Sp2 overlap count is 204\n",
      "hi_6585 Sp1 overlap count is 168\n",
      "hi_6585 Sp2 overlap count is 168\n",
      "hi_1580 Sp1 overlap count is 376\n",
      "hi_1580 Sp2 overlap count is 376\n",
      "hi_2142 Sp1 overlap count is 274\n",
      "hi_2142 Sp2 overlap count is 274\n",
      "hi_2148 Sp1 overlap count is 224\n",
      "hi_2148 Sp2 overlap count is 224\n",
      "hi_2156 Sp1 overlap count is 270\n",
      "hi_2156 Sp2 overlap count is 270\n",
      "hi_4115 Sp1 overlap count is 300\n",
      "hi_4115 Sp2 overlap count is 300\n",
      "hi_4214 Sp1 overlap count is 292\n",
      "hi_4214 Sp2 overlap count is 292\n",
      "hi_4284 Sp1 overlap count is 280\n",
      "hi_4284 Sp2 overlap count is 280\n",
      "hi_4360 Sp1 overlap count is 600\n",
      "hi_4360 Sp2 overlap count is 600\n",
      "hi_4649 Sp1 overlap count is 290\n",
      "hi_4649 Sp2 overlap count is 290\n",
      "hi_4770 Sp1 overlap count is 626\n",
      "hi_4770 Sp2 overlap count is 626\n",
      "hi_6256 Sp1 overlap count is 342\n",
      "hi_6256 Sp2 overlap count is 342\n",
      "hi_6270 Sp1 overlap count is 326\n",
      "hi_6270 Sp2 overlap count is 326\n",
      "hi_6289 Sp1 overlap count is 436\n",
      "hi_6289 Sp2 overlap count is 436\n",
      "hi_6300 Sp1 overlap count is 798\n",
      "hi_6300 Sp2 overlap count is 798\n",
      "hi_6400 Sp1 overlap count is 262\n",
      "hi_6400 Sp2 overlap count is 262\n",
      "hi_6412 Sp1 overlap count is 284\n",
      "hi_6412 Sp2 overlap count is 284\n",
      "hi_1385 Sp1 overlap count is 176\n",
      "hi_1385 Sp2 overlap count is 176\n",
      "hi_4370 Sp1 overlap count is 134\n",
      "hi_4370 Sp2 overlap count is 134\n",
      "hi_6322 Sp1 overlap count is 100\n",
      "hi_6322 Sp2 overlap count is 100\n"
     ]
    }
   ],
   "source": [
    "#Giving directory path of csv input files to checks function                \n",
    "path = \"/content/drive/MyDrive/HD Corpus/Files/\"\n",
    "checks(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4YjlVmh0a_84",
   "metadata": {
    "id": "4YjlVmh0a_84"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Checks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
