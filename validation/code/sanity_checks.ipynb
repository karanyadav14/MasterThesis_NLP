{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e3f7b95-f82c-4ce0-b75b-0df0d951d9fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install pyconll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "778c5432-ba8e-4240-a62a-acb4715e583c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## ToDo\n",
    "## Mention in ReadME\n",
    "    ## Run this script iteratively to ensure prerequisite of number of columns for some checks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ec8f684-c2f9-4632-9895-e2850772f859",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## ToDo Done\n",
    "## NestedTag value must be True\n",
    "## Coref value must be Int\n",
    "## Value in quotation should be part of token\n",
    "## Value in misc should not have backslash \n",
    "## Value should either be Matrix_Tag, True or string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5c2011b-d4ca-4a1c-99b4-a66fab5c6151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## ToDO ##Done\n",
    "## Head should be integer\n",
    "## Ensure single punctuation\n",
    "## Head of root should be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c03ca26-7ee1-42ea-a255-2a9820d0ac4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Validate lemmma and form ##Done\n",
    "## If not devnagari and int it should be from predefined list ['pause',..]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c108bda-16b6-40e7-a506-bf95e4662d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## ToDo\n",
    "## More than one occurence of deprel and if they have same head, then\n",
    "## check whether second occurence should have coref of token of first occurence of deprel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dbebb1da-0bce-44ad-b448-dc8c87bfe5c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## ToDo\n",
    "## Head should not be token id of same token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55adcb55-978f-4103-afb2-a60d3a53afdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pyconll "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b30f2627-c6e2-45d9-a22d-54007a4b3b09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepath = \"../../parse_gold/\" ## path where gold data is stored in phase wise manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fba8f190-adfb-473d-be23-881be213bb79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dirs = sorted(os.listdir(filepath)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b661e85-0f05-4da5-98e7-dba759645e80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# validate_columns(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0568ef89-9009-49ab-b1e1-d8e4c4515011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ee55e7d-802a-43cd-9dd1-3d80e4b86508",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_whitespace(line):\n",
    "    pattern = re.compile(r'(?!\\t)(?!\\n)\\s+')\n",
    "    matches = pattern.finditer(line)\n",
    "    results = []\n",
    "    for match in matches:\n",
    "        start = match.start()\n",
    "        \n",
    "        whitespace = match.group()\n",
    "        context = line[max(0, start - 4):start + 4]\n",
    "        results.append((whitespace, context))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "545119c1-fb80-4bba-bbbb-6c6ca94eb0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_whitespace_meta_data(line):\n",
    "    pattern = re.compile(r'(?!\\t)(?!\\n)\\s{2,}')\n",
    "    matches = pattern.finditer(line)\n",
    "    results = []\n",
    "    for match in matches:\n",
    "        start = match.start()\n",
    "        \n",
    "        whitespace = match.group()\n",
    "        context = line[max(0, start - 4):start + 4]\n",
    "        results.append((whitespace, context))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "755bab2a-10e0-467c-804a-f27660d9f338",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_whitespaces(output_file_path):\n",
    "    sent_id = 0\n",
    "    list_failed_validate_whitespaces = []\n",
    "    list_failed_validate_whitespaces_meta = []\n",
    "    with open(output_file_path, 'r') as output_file:\n",
    "        for line in output_file:\n",
    "                        \n",
    "            if \"sent_id\" in line:\n",
    "                sent_id += 1\n",
    "                \n",
    "            if line.startswith(\"#\") or line.startswith(\"\\n\"):\n",
    "                res = find_whitespace_meta_data(line)\n",
    "                if len(res)!=0:\n",
    "                    list_failed_validate_whitespaces_meta.append([(f\"Sentence Id: {sent_id}\"),(f\"More than one whitespaces: {res}\")])\n",
    "\n",
    "                continue\n",
    "            \n",
    "            # whitespaces = re.findall(\"\\s\", line)\n",
    "            whitespaces = find_whitespace(line)\n",
    "            if len(whitespaces)!=0:\n",
    "                token_id = re.findall(r'\\d+', line)[0]\n",
    "                list_failed_validate_whitespaces.append([(f\"Sentence Id: {sent_id}\"), (f\"Token Id: {token_id}\"), (f\"Whitespaces: {whitespaces}\")])\n",
    "    \n",
    "    return list_failed_validate_whitespaces, list_failed_validate_whitespaces_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4479333a-0b8d-4649-ae9d-a8fe11104e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "301b41c5-88ed-4bb4-b77a-56bb246696e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_newline(output_file_path):\n",
    "    sent_id = 0\n",
    "    list_failed_validate_newline = []\n",
    "    with open(output_file_path, 'r') as output_file:\n",
    "        for line in output_file:\n",
    "            if \"sent_id\" in line:\n",
    "                sent_id += 1\n",
    "            if line.startswith(\"#\") or line.startswith(\"\\n\"):\n",
    "                continue\n",
    "            if '\\n' not in line:\n",
    "                token_id = re.findall(r'\\d+', line)[0]\n",
    "                list_failed_validate_newline.append([(f\"Sentence Id: {sent_id}\"), (f\"Token Id: {token_id}\"), (\"No new line character is present\")])\n",
    "        \n",
    "    return list_failed_validate_newline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fad8fbe7-1ffb-4fb4-aa7d-383a1c11c87d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_columns(line):\n",
    "    # import pdb;pdb.set_trace()\n",
    "    cols = (line.split(\"\\t\"))\n",
    "    col_count = len(cols)\n",
    "    tabs = re.findall(r'\\t{2,}', line)  ## Look for more than one consecutive tabs\n",
    "    if col_count != 10:\n",
    "        return f\"Number of columns: {col_count}\"\n",
    "    elif len(tabs)!=0:\n",
    "        return \"Empty column found\"\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1d0af10-c187-4bd1-8db3-fef54a03f9dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_num_cols(output_file_path):\n",
    "    \n",
    "    # file = os.path.basename(output_file_path)\n",
    "    sent_id = 0\n",
    "    list_failed_validate_num_cols = []\n",
    "    with open(output_file_path, 'r') as output_file:\n",
    "        for line in output_file:\n",
    "            if \"sent_id\" in line:\n",
    "                sent_id += 1\n",
    "            if line.startswith(\"#\") or line.startswith(\"\\n\"):\n",
    "                continue\n",
    "            # print(line)\n",
    "            col_count = validate_columns(line)\n",
    "            if col_count:\n",
    "                token_id = re.findall(r'\\d+', line)[0]\n",
    "                # print(line[0])\n",
    "                # print(file, sent_id, col_count)\n",
    "                list_failed_validate_num_cols.append([(f\"Sentence Id: {sent_id}\"), (f\"Token Id: {token_id}\"), (col_count)])\n",
    "   \n",
    "        \n",
    "        \n",
    "    return list_failed_validate_num_cols\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6d32146-ae94-4cfe-953e-4a57d2fa6902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_undescores(output_file_path):\n",
    "    sent_id = 0\n",
    "    list_underscores = []\n",
    "    with open(output_file_path, 'r') as output_file:\n",
    "        for line in output_file:\n",
    "            if \"sent_id\" in line:\n",
    "                sent_id_in_file = int(re.findall(r'\\d+', line)[0])\n",
    "                \n",
    "            underscores = re.findall(r'\\_{2,}', line)\n",
    "            if len(underscores)!=0:\n",
    "                list_underscores.append([(f\"Sentence Id in the file: {sent_id_in_file}\"), (f\"More that one underscores found in {line}\")])\n",
    "                \n",
    "    return list_underscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a0f24fb-9c5f-4ee4-a777-b31c7bd86bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_sent_token_id(output_file_path):\n",
    "    sent_id = 0\n",
    "    token_id = 0\n",
    "    list_failed_validate_sent_id = []\n",
    "    list_failed_validate_token_id = []\n",
    "    list_failed_validate_no_token_id = []\n",
    "    with open(output_file_path, 'r') as output_file:\n",
    "        for line in output_file:\n",
    "            if \"sent_id\" in line:\n",
    "                if token_id>0:\n",
    "                    last_token_prev_sent = token_id\n",
    "                    # import pdb;pdb.set_trace()\n",
    "                    if last_token_prev_sent!=total_tokens_meta:\n",
    "                        list_failed_validate_no_token_id.append([(f\"Sentence Id in the file: {sent_id_in_file+1}\"), \"Mismatch between no of tokens in meta sentence and token ids\"])\n",
    "                token_id = 0\n",
    "                sent_id += 1\n",
    "                sent_id_in_file = int(re.findall(r'\\d+', line)[0])\n",
    "                if sent_id != sent_id_in_file:\n",
    "                    list_failed_validate_sent_id.append([(f\"Required Sentence Id: {sent_id}\"), (f\"Sentence Id in the file: {sent_id_in_file}\")])\n",
    "                # list_failed_validate_token_id.append(\"$\"*100)\n",
    "            \n",
    "            if \"Sentence\" in line:\n",
    "                sent_string = line.split(\"=\")[1]\n",
    "                tokens = sent_string.split(\" \")\n",
    "                # print(tokens)\n",
    "                total_tokens_meta = len(tokens)-1\n",
    "                # print(total_tokens_meta)\n",
    "            \n",
    "            \n",
    "\n",
    "            if line.startswith(\"#\") or line.startswith(\"\\n\"):\n",
    "                continue\n",
    "                \n",
    "            token_id +=1\n",
    "            token_id_in_file = int(re.findall(r'\\d+', line)[0])\n",
    "            if token_id != token_id_in_file:\n",
    "                list_failed_validate_token_id.append([(f\"Sentence Id in the file: {sent_id_in_file}\"),(f\"Required Token Id: {token_id}\"), (f\"Token Id in the file: {token_id_in_file}\")])\n",
    "            \n",
    "            \n",
    "            \n",
    "            # if total_tokens_meta\n",
    "                \n",
    "                # import pdb;pdb.set_trace()\n",
    "    return list_failed_validate_sent_id, list_failed_validate_token_id, list_failed_validate_no_token_id\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "074f0761-9575-4c0a-a391-328f510c5217",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_attributes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49fda5a0-b228-40d3-8f8e-6113bd52f682",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ओए', 'तुम', 'सुन', 'रहे', 'ना']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.findall(r'[\\u0900-\\u097F]+', \"ओए तुम dfg सुन रहे ना\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "370f211c-1481-467b-af9c-e2cc4e73d1d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_lemma_form(output_file_path, list_attributes):\n",
    "    sent_id = 0\n",
    "    token_id = 0\n",
    "    list_failed_upos = []\n",
    "    list_failed_deprel = []\n",
    "    with open(output_file_path, 'r') as output_file:\n",
    "        for line in output_file:\n",
    "            if \"sent_id\" in line:\n",
    "                token_id = 0\n",
    "                sent_id_in_file = int(re.findall(r'\\d+', line)[0])\n",
    "            \n",
    "            if line.startswith(\"#\") or line.startswith(\"\\n\"):\n",
    "                continue\n",
    "            \n",
    "            token_id += 1\n",
    "            if not (validate_columns(line)):\n",
    "                form = line.split(\"\\t\")[1]\n",
    "                lemma = line.split(\"\\t\")[2]\n",
    "                \n",
    "                devanagari_words = re.findall(r'[\\u0900-\\u097F]+', form)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236c8b9e-909f-4ce7-a5f3-c9dad22d4e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a88d46ae-097a-4432-81be-775729726633",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_deprel = '''acl\n",
    "acl:relcl\n",
    "advcl\n",
    "advmod\n",
    "amod\n",
    "aux\n",
    "aux:pass\n",
    "case\n",
    "cc\n",
    "compound\n",
    "conj\n",
    "cop\n",
    "dep\n",
    "det\n",
    "dislocated\n",
    "iobj\n",
    "mark\n",
    "nmod\n",
    "nsubj\n",
    "nsubj:pass\n",
    "nummod\n",
    "obj\n",
    "obl\n",
    "punct\n",
    "reparandum\n",
    "root\n",
    "vocative\n",
    "xcomp'''.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cbfb4e4-6461-485e-a4e8-1fe98b787c7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_deprel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96651524-14c4-4d6e-ad1e-1bf9ce498650",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_upos = '''ADJ\n",
    "ADP\n",
    "ADV\n",
    "AUX\n",
    "CCONJ\n",
    "DET\n",
    "INTJ\n",
    "NOUN\n",
    "NUM\n",
    "PART\n",
    "PRON\n",
    "PROPN\n",
    "PUNCT\n",
    "SCONJ\n",
    "VERB\n",
    "X'''.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bf7c1af-9369-4d73-af0f-9117df32b988",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_upos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aad42799-02f2-4730-a8d3-864c119502c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_upos_deprel(output_file_path, list_upos, list_deprel):\n",
    "    sent_id = 0\n",
    "    token_id = 0\n",
    "    list_failed_upos = []\n",
    "    list_failed_deprel = []\n",
    "    with open(output_file_path, 'r') as output_file:\n",
    "        for line in output_file:\n",
    "            if \"sent_id\" in line:\n",
    "                token_id = 0\n",
    "                sent_id_in_file = int(re.findall(r'\\d+', line)[0])\n",
    "            \n",
    "            if line.startswith(\"#\") or line.startswith(\"\\n\"):\n",
    "                continue\n",
    "            \n",
    "            token_id += 1\n",
    "            if not (validate_columns(line)):\n",
    "                upos = line.split(\"\\t\")[3]\n",
    "                deprel = line.split(\"\\t\")[7]\n",
    "                if upos not in list_upos:\n",
    "                    list_failed_upos.append([(f\"Sentence Id in the file: {sent_id_in_file}\"),(f\"Required Token Id: {token_id}\"), (f\"Incorrect upos found : {upos}\")])\n",
    "            \n",
    "                colons = re.findall(r'\\:', deprel)  ## can be removed\n",
    "                # print(deprel)\n",
    "                # import pdb;pdb.set_trace()\n",
    "                count_colon = len(colons)\n",
    "                if (deprel not in list_deprel) or (count_colon>1):\n",
    "                    list_failed_deprel.append([(f\"Sentence Id in the file: {sent_id_in_file}\"),(f\"Required Token Id: {token_id}\"), (f\"Incorrect deprel found : {deprel}\")])\n",
    "                # break\n",
    "    return list_failed_upos, list_failed_deprel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17b4ca3-cbbe-4959-88e3-b17e897505c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31b6e2e0-e839-4d30-b69a-e3be67fa1bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_root_punct(output_file_path):\n",
    "    ## ToDO\n",
    "    ## Head should be integer\n",
    "    ## Ensure single punctuation\n",
    "    ## Head of root should be 0\n",
    "    sent_id = 0\n",
    "    token_id = 0\n",
    "    root_token_id = 0\n",
    "    list_root = []\n",
    "    list_punct = []\n",
    "    list_failed_root = []\n",
    "    list_failed_punct = []\n",
    "    list_failed_head = []\n",
    "    with open(output_file_path, 'r') as output_file:\n",
    "        for line in output_file:\n",
    "            if \"sent_id\" in line:\n",
    "                list_root = []\n",
    "                list_punct = []\n",
    "                token_id = 0\n",
    "                sent_id_in_file = int(re.findall(r'\\d+', line)[0])\n",
    "            \n",
    "            if line.startswith(\"#\") or line.startswith(\"\\n\"):\n",
    "                continue\n",
    "            \n",
    "            token_id += 1\n",
    "            if not (validate_columns(line)):  ## Case when columns are equal to 10\n",
    "                upos = line.split(\"\\t\")[3]\n",
    "                deprel = line.split(\"\\t\")[7]\n",
    "                head = int(line.split(\"\\t\")[6])\n",
    "                \n",
    "                if not isinstance(head, int):\n",
    "                    list_failed_head.append([(f\"Sentence Id in the file: {sent_id_in_file}\"),(f\"Token Id: {token_id}\"), (f\"Head is not an integer\")])\n",
    "                \n",
    "                if deprel == 'root':\n",
    "                    root_head = int(line.split(\"\\t\")[6])\n",
    "                    root_token_id = token_id\n",
    "                    list_root.append(deprel)\n",
    "                    if root_head !=0:\n",
    "                        list_failed_root.append([(f\"Sentence Id in the file: {sent_id_in_file}\"),(f\"Token Id: {token_id}\"), (f\"Wrong head of root: {root_head}\")])\n",
    "\n",
    "                if len(list_root)>1:\n",
    "                    list_failed_root.append([(f\"Sentence Id in the file: {sent_id_in_file}\"),(f\"Token Id: {token_id}\"), (f\"More than one root found\")])\n",
    "                \n",
    "                if upos == 'PUNCT':\n",
    "                    # import pdb;pdb.set_trace()\n",
    "                    head = int(line.split(\"\\t\")[6])\n",
    "                    list_punct.append(upos)\n",
    "                    if head!=root_token_id:\n",
    "                        list_failed_punct.append([(f\"Sentence Id in the file: {sent_id_in_file}\"),(f\"Token Id: {token_id}\"), (f\"Head of PUNCT is {head} and not root token_id {root_token_id}\")])\n",
    "                    \n",
    "                    if len(list_punct)>1:\n",
    "                        list_failed_punct.append([(f\"Sentence Id in the file: {sent_id_in_file}\"),(f\"More than one punctuation upos found\")])\n",
    "\n",
    "    return list_failed_root, list_failed_punct, list_failed_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c983214-d6fd-4a04-9884-04cb702e547b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_tags = ['Repair',  ## To be cross verify with data\n",
    " 'CodeSwitch',\n",
    " 'Disfluency',\n",
    " 'Hesitation',\n",
    " 'Expletive',\n",
    " 'Quote',\n",
    " 'NestedTag',\n",
    " 'Coref']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5dccd41-351b-41c3-9537-eebea3fc07d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_misc(output_file_path, list_tags):\n",
    "    ## ToDo\n",
    "    ## NestedTag value must be True\n",
    "    ## Coref value must be Int\n",
    "    ## Value in quotation should be part of token\n",
    "    ## Value in misc should not have backslash \n",
    "    ## Value should either be Matrix_Tag or string \n",
    "    sent_id = 0\n",
    "    token_id = 0\n",
    "    list_root = []\n",
    "    list_failed_misc = []\n",
    "    with open(output_file_path, 'r') as output_file:\n",
    "        for line in output_file:\n",
    "            if \"sent_id\" in line:\n",
    "                list_root = []\n",
    "                token_id = 0\n",
    "                sent_id_in_file = int(re.findall(r'\\d+', line)[0])\n",
    "            \n",
    "            if line.startswith(\"#\") or line.startswith(\"\\n\"):\n",
    "                continue\n",
    "            \n",
    "            token_id += 1\n",
    "            if not (validate_columns(line)):  ## Case when columns are equal to 10\n",
    "                misc = line.split(\"\\t\")[9]\n",
    "                misc = misc.strip('\\n')\n",
    "                if misc != \"_\":\n",
    "                    if \"|\" in misc:\n",
    "                        misc_list = misc.split(\"|\")\n",
    "                        for misc_attributes in misc_list:\n",
    "                            key = misc_attributes.split(\"=\")[0]\n",
    "                            value = misc_attributes.split(\"=\")[1]\n",
    "                            \n",
    "                            if key not in list_tags:\n",
    "                                list_failed_misc.append([(f\"Sentence Id in the file: {sent_id_in_file}\"),(f\"Token Id: {token_id}\"), (f\"Incorrect annotation found in misc {key}\")])\n",
    "                            # elif isinstance(value, str):\n",
    "                                \n",
    "                            elif key==\"NestedTag\" and value!=\"True\":\n",
    "                                list_failed_misc.append([(f\"Sentence Id in the file: {sent_id_in_file}\"),(f\"Token Id: {token_id}\"), (f\"Incorrect annotation found in misc {key, value}\")])\n",
    "                            \n",
    "                            elif key ==\"Coref\" and isinstance(int(value), int):\n",
    "                                list_failed_misc.append([(f\"Sentence Id in the file: {sent_id_in_file}\"),(f\"Token Id: {token_id}\"), (f\"Incorrect value found in misc {value}\")])\n",
    "                            elif \"\\\\\" in value:  \n",
    "                                list_failed_misc.append([(f\"Sentence Id in the file: {sent_id_in_file}\"),(f\"Token Id: {token_id}\"), (f\"Incorrect value found in misc {value}\")])\n",
    "                        \n",
    "                                \n",
    "                    else:\n",
    "                        misc_list = misc.split(\"=\")\n",
    "                        key = misc_list[0]\n",
    "                        value = misc_list[1]\n",
    "                        \n",
    "                        if key not in list_tags:\n",
    "                            list_failed_misc.append([(f\"Sentence Id in the file: {sent_id_in_file}\"),(f\"Token Id: {token_id}\"), (f\"Incorrect annotation found in misc {key}\")])\n",
    "                        elif key==\"NestedTag\" and value!=\"True\":\n",
    "                            list_failed_misc.append([(f\"Sentence Id in the file: {sent_id_in_file}\"),(f\"Token Id: {token_id}\"), (f\"Incorrect annotation found in misc {key, value}\")])\n",
    "                        elif key ==\"Coref\" and isinstance(int(value), int):\n",
    "                            list_failed_misc.append([(f\"Sentence Id in the file: {sent_id_in_file}\"),(f\"Token Id: {token_id}\"), (f\"Incorrect value found in misc {value}\")])\n",
    "                        elif \"\\\\\" in value:  \n",
    "                            list_failed_misc.append([(f\"Sentence Id in the file: {sent_id_in_file}\"),(f\"Token Id: {token_id}\"), (f\"Incorrect value found in misc {value}\")])\n",
    "\n",
    "                            \n",
    "                            \n",
    "    return list_failed_misc\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26693139-f57b-4436-abd6-2be4b5fdba24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({(3, 'abc'): 1, (1, 'abc'): 2})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# import counter class from collections module\n",
    "from collections import Counter\n",
    "Counter([(3,'abc'), (1,'abc') , (1,'abc')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90db71cb-f3a2-4a33-8487-ea5bfdaeb8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Validate lemmma and form\n",
    "## If not devnagari and int it should be from predefined list ['pause',..]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "697a5673-a139-45bd-a784-45cb05c068c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# re.findall(\"^(?!.*[\\u0900-\\u097F])(?!^\\d+$)\\w+$\", \"laughter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42ad878a-d0e6-429a-b387-fbc515b8dfbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# pattern = r\"[\\u0900-\\u097F]|\\d+|[pause]|[aside]|[b_aside]|[e_aside]|[laughter]|[noise]|[incomprehensible]\"\n",
    "# text = \"[pause]\"\n",
    "\n",
    "# matches = re.findall(pattern, text)\n",
    "# print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5752777-87e8-486d-a7d0-ae97951f317e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# att_list = [\"[pause]\", \"[aside]\", \"[b_aside]\", \"[e_aside]\", \"[laughter]\", \"[noise]\", \"[incomprehensible]\"]\n",
    "# check_form_lemma( \"11\", att_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31e081ec-8d48-4b64-b17d-db614fe28a43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_form_lemma(string, attribute_list):\n",
    " \n",
    "    if string not in attribute_list: \n",
    "        if \"_\" not in string:\n",
    "            devanagari_pattern = r'[\\u0900-\\u097F]'\n",
    "            devnagari_pattern = f'{devanagari_pattern}'\n",
    "            devnagari = re.findall(devnagari_pattern, string)\n",
    "            flag_devnagari = len(devnagari) == len(string)\n",
    "\n",
    "            integer_pattern = r'\\d+'\n",
    "            digit_str = re.findall(integer_pattern, string)\n",
    "            # import pdb;pdb.set_trace()\n",
    "            try:\n",
    "                digit_int = int(digit_str[0])\n",
    "                flag_integer = isinstance(digit_int, int)\n",
    "            except:\n",
    "                flag_integer = False\n",
    "                \n",
    "            # flag = flag_devnagari or flag_integer\n",
    "        else:\n",
    "            string_list = string.split(\"_\")\n",
    "            flag = False\n",
    "            for string in string_list:\n",
    "                flag = flag or check_form_lemma(string, attribute_list)\n",
    "                \n",
    "    elif string in attribute_list:\n",
    "        flag = True\n",
    "    else:\n",
    "        flag = False\n",
    "    \n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb474791-6421-4f4c-89e4-c1763c55ccb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_form_lemma(output_file_path):\n",
    "    sent_id = 0\n",
    "    token_id = 0\n",
    "    list_failed_form = []\n",
    "    list_failed_lemma = []\n",
    "    attribute_list = [\"[pause]\", \"[aside]\", \"[b_aside]\", \"[e_aside]\", \"[laughter]\", \"[noise]\", \"[incomprehensible]\", \"।\", \"[anonymized]\"]\n",
    "    with open(output_file_path, 'r') as output_file:\n",
    "        for line in output_file:\n",
    "            if \"sent_id\" in line:\n",
    "                token_id = 0\n",
    "                sent_id_in_file = int(re.findall(r'\\d+', line)[0])\n",
    "            \n",
    "            if line.startswith(\"#\") or line.startswith(\"\\n\"):\n",
    "                continue\n",
    "            \n",
    "            token_id += 1\n",
    "            if not (validate_columns(line)):  ## Case when columns are equal to 10\n",
    "                form = line.split(\"\\t\")[1]\n",
    "                lemma = line.split(\"\\t\")[2]\n",
    "        \n",
    "                \n",
    "                if not check_form_lemma(form, attribute_list):\n",
    "                    list_failed_form.append([(f\"Sentence Id in the file: {sent_id_in_file}\"),(f\"Token Id: {token_id}\"), (f\"Incorrect form found {form}\")])\n",
    "                if not check_form_lemma(lemma, attribute_list):\n",
    "                    list_failed_lemma.append([(f\"Sentence Id in the file: {sent_id_in_file}\"),(f\"Token Id: {token_id}\"), (f\"Incorrect form found {lemma}\")])\n",
    "    \n",
    "    return list_failed_form, list_failed_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2aec36-4642-4882-bad5-d314402f2b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be4cd896-d2d5-45b3-b444-0630a59602d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_subj_obj(output_file_path):\n",
    "    ## ToDo\n",
    "    ## More than one occurence of deprel and if they have same head, then\n",
    "    ## check whether second occurence should have coref of token of first occurence of deprel\n",
    "    sent_id = 0\n",
    "    token_id = 0\n",
    "    list_failed_subj_obj = []\n",
    "    deprel_list = []\n",
    "    deprel_dict = {}\n",
    "    deprel_check = ['nsubj', 'obj', 'iobj']\n",
    "    with open(output_file_path, 'r') as output_file:\n",
    "        for line in output_file:\n",
    "            if \"sent_id\" in line:\n",
    "                token_id = 0\n",
    "                deprel_list = []\n",
    "                deprel_dict = {}\n",
    "                sent_id_in_file = int(re.findall(r'\\d+', line)[0])\n",
    "            \n",
    "            if line.startswith(\"#\") or line.startswith(\"\\n\"):\n",
    "                continue\n",
    "            \n",
    "            token_id += 1\n",
    "            if not (validate_columns(line)):  ## Case when columns are equal to 10\n",
    "                head = line.split(\"\\t\")[6]\n",
    "                deprel = line.split(\"\\t\")[7]\n",
    "                misc = line.split(\"\\t\")[9]\n",
    "                misc = misc.replace(\"\\n\", \"\")\n",
    "                \n",
    "                if deprel in deprel_check:\n",
    "                    # for i in deprel:\n",
    "                    deprel_list.append((head, deprel))\n",
    "                    deprel_dict.update({(head, deprel):token_id})\n",
    "                    deprel_count = Counter(deprel_list)     \n",
    "                    print(deprel_count)\n",
    "                    for _, count in deprel_count.items():\n",
    "                        print(count)\n",
    "                        if count>1:\n",
    "                            # import pdb;pdb.set_trace()\n",
    "                            if \"_\" in misc:\n",
    "                                print(\"#############\")\n",
    "                                list_failed_subj_obj.append([(f\"Sentence Id in the file: {sent_id_in_file}\"),(f\"Token Id: {token_id}\"), (f\"Incorrect Coref in misc: {misc}\")])\n",
    "                            else:\n",
    "                                misc_list = misc.split(\"=\")\n",
    "                                \n",
    "                                print(misc_list, sent_id_in_file,token_id, output_file_path)\n",
    "                                coref_file = misc_list[1]\n",
    "                                req_coref = deprel_dict[(head,deprel)]\n",
    "\n",
    "                                if int(coref_file)!=int(req_coref):\n",
    "                                    list_failed_subj_obj.append([(f\"Sentence Id in the file: {sent_id_in_file}\"),(f\"Token Id: {token_id}\"), (f\"Incorrect Coref in misc: {misc}\")])\n",
    "                            count =0\n",
    "                            # deprel_to_check = deprel\n",
    "\n",
    "                \n",
    "                \n",
    "    return list_failed_subj_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "479a6d19-08b9-4603-a6ec-0e67c113f6e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sanity_checks = []\n",
    "\n",
    "for phase in dirs:\n",
    "    if not os.path.isfile(os.path.join(filepath, phase)):    \n",
    "        phase_path = os.path.join(filepath, phase)\n",
    "        output_files = sorted(os.listdir(phase_path))\n",
    "        # sanity_checks['phase'] = phase\n",
    "        for file in output_files:\n",
    "            output_file_path = os.path.join(phase_path, file)\n",
    "            if os.path.isfile(output_file_path):\n",
    "                        \n",
    "                        \n",
    "                # validate number of columns\n",
    "                sanity_check_cols = validate_num_cols(output_file_path)\n",
    "                # print(sanity_check_cols)\n",
    "                if len(sanity_check_cols)!=0:\n",
    "                    sanity_checks.append([phase, file, 'validate_num_cols',  sanity_check_cols])\n",
    "            \n",
    "                \n",
    "                ## Validate whitespaces\n",
    "                sanity_check_whitespaces,sanity_check_whitespaces_meta = validate_whitespaces(output_file_path)\n",
    "                if len(sanity_check_whitespaces)!=0:\n",
    "                    sanity_checks.append([phase, file, 'validate_whitespaces', sanity_check_whitespaces])\n",
    "                if len(sanity_check_whitespaces_meta)!=0:\n",
    "                    sanity_checks.append([phase, file, 'meta_data_validate_whitespaces', sanity_check_whitespaces_meta])\n",
    "                \n",
    "                \n",
    "                ## Validate newline character at every row\n",
    "#                 sanity_check_newline_char = validate_newline(output_file_path)\n",
    "#                 if len(sanity_check_newline_char)!=0:\n",
    "#                     sanity_checks.append([phase, file, 'validate_newline_char', sanity_check_newline_char])\n",
    "                    \n",
    "                    \n",
    "                ## validate sequence of sentence id and token id\n",
    "                sanity_check_sent_id, sanity_check_token_id, sanity_check_num_token_id = validate_sent_token_id(output_file_path)\n",
    "                if len(sanity_check_sent_id)!=0:\n",
    "                    sanity_checks.append([phase, file, 'validate_sent_id_sequence', sanity_check_sent_id])\n",
    "                if len(sanity_check_token_id)!=0:\n",
    "                    sanity_checks.append([phase, file, 'validate_token_id_sequence', sanity_check_token_id])\n",
    "                # print(sanity_check_num_token_id)\n",
    "                if len(sanity_check_num_token_id)!=0:\n",
    "                    sanity_checks.append([phase, file, 'validate_num_token_id_sequence', sanity_check_num_token_id])\n",
    "                                \n",
    "                ## validate double underscores\n",
    "                sanity_check_list_underscores = validate_undescores(output_file_path)\n",
    "                # print(sanity_check_list_underscores)\n",
    "                if len(sanity_check_list_underscores)!=0:\n",
    "                    sanity_checks.append([phase, file, 'validate_underscores', sanity_check_list_underscores])\n",
    "\n",
    "\n",
    "                    \n",
    "                ## validate annotations tags\n",
    "                # sanity_check_annotation_tags = validate_annotation_tags(output_file_path)\n",
    "                # if len(sanity_check_annotation_tags)!=0:\n",
    "                \n",
    "                 # Validate form and lemma\n",
    "                # sanity_check_form,sanity_check_lemma  = validate_form_lemma(output_file_path)\n",
    "                # if len(sanity_check_form)!=0:\n",
    "                #     sanity_checks.append([phase, file, 'validate_form', sanity_check_form])\n",
    "                # if len(sanity_check_lemma)!=0:\n",
    "                #     sanity_checks.append([phase, file, 'validate_lemma', sanity_check_lemma])\n",
    "                \n",
    "        \n",
    "            \n",
    "                ## Validate deprel\n",
    "                sanity_check_upos, sanity_check_deprel = validate_upos_deprel(output_file_path, list_upos, list_deprel)\n",
    "                if len(sanity_check_upos)!=0:\n",
    "                    sanity_checks.append([phase, file, 'validate_upos', sanity_check_upos])\n",
    "                if len(sanity_check_deprel)!=0:\n",
    "                    sanity_checks.append([phase, file, 'validate_deprels', sanity_check_deprel])\n",
    "                    \n",
    "                ## Validate root and punctuation\n",
    "                sanity_check_root, sanity_check_punct, sanity_check_head = validate_root_punct(output_file_path)\n",
    "                if len(sanity_check_root)!=0:\n",
    "                    sanity_checks.append([phase, file, 'validate_root', sanity_check_root])\n",
    "                if len(sanity_check_punct)!=0:\n",
    "                    sanity_checks.append([phase, file, 'validate_punct', sanity_check_punct])\n",
    "                if len(sanity_check_head)!=0:\n",
    "                    sanity_checks.append([phase, file, 'validate_head', sanity_check_head])\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                ## Validate Misc\n",
    "                sanity_check_misc = validate_misc(output_file_path, list_tags)\n",
    "                if len(sanity_check_misc)!=0:\n",
    "                    sanity_checks.append([phase, file, 'validate_misc', sanity_check_misc])\n",
    "                    \n",
    "                ## Validate subj/obj\n",
    "                # sanity_check_coref = validate_subj_obj(output_file_path)\n",
    "                # if len(sanity_check_coref)!=0:\n",
    "                #     sanity_checks.append([phase, file, 'validate_coref', sanity_check_coref])\n",
    "                \n",
    "               \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62c65524-5c4b-4afb-b517-ead984955cb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Phase1',\n",
       "  'hi_1385_gold.conllu',\n",
       "  'validate_num_cols',\n",
       "  [['Sentence Id: 5', 'Token Id: 6', 'Empty column found']]],\n",
       " ['Phase1',\n",
       "  'hi_4370_gold.conllu',\n",
       "  'validate_misc',\n",
       "  [['Sentence Id in the file: 121',\n",
       "    'Token Id: 8',\n",
       "    'Incorrect value found in misc 3'],\n",
       "   ['Sentence Id in the file: 284',\n",
       "    'Token Id: 11',\n",
       "    'Incorrect value found in misc 8'],\n",
       "   ['Sentence Id in the file: 292',\n",
       "    'Token Id: 17',\n",
       "    'Incorrect value found in misc 12']]],\n",
       " ['Phase1',\n",
       "  'hi_6322_gold.conllu',\n",
       "  'validate_punct',\n",
       "  [['Sentence Id in the file: 103',\n",
       "    'Token Id: 14',\n",
       "    'Head of PUNCT is 12 and not root token_id 5'],\n",
       "   ['Sentence Id in the file: 198',\n",
       "    'Token Id: 12',\n",
       "    'Head of PUNCT is 8 and not root token_id 2'],\n",
       "   ['Sentence Id in the file: 440',\n",
       "    'Token Id: 9',\n",
       "    'Head of PUNCT is 6 and not root token_id 3'],\n",
       "   ['Sentence Id in the file: 622',\n",
       "    'Token Id: 7',\n",
       "    'Head of PUNCT is 4 and not root token_id 1']]],\n",
       " ['Phase1',\n",
       "  'hi_6322_gold.conllu',\n",
       "  'validate_misc',\n",
       "  [['Sentence Id in the file: 122',\n",
       "    'Token Id: 17',\n",
       "    'Incorrect value found in misc 10'],\n",
       "   ['Sentence Id in the file: 151',\n",
       "    'Token Id: 6',\n",
       "    'Incorrect value found in misc 2'],\n",
       "   ['Sentence Id in the file: 282',\n",
       "    'Token Id: 4',\n",
       "    'Incorrect value found in misc 2']]],\n",
       " ['Phase1',\n",
       "  'hi_6435_gold.conllu',\n",
       "  'validate_punct',\n",
       "  [['Sentence Id in the file: 19',\n",
       "    'Token Id: 8',\n",
       "    'Head of PUNCT is 5 and not root token_id 2'],\n",
       "   ['Sentence Id in the file: 96',\n",
       "    'Token Id: 13',\n",
       "    'Head of PUNCT is 11 and not root token_id 5'],\n",
       "   ['Sentence Id in the file: 294',\n",
       "    'Token Id: 10',\n",
       "    'Head of PUNCT is 8 and not root token_id 5'],\n",
       "   ['Sentence Id in the file: 461',\n",
       "    'Token Id: 7',\n",
       "    'Head of PUNCT is 5 and not root token_id 3'],\n",
       "   ['Sentence Id in the file: 496',\n",
       "    'Token Id: 11',\n",
       "    'Head of PUNCT is 8 and not root token_id 2']]],\n",
       " ['Phase1',\n",
       "  'hi_6435_gold.conllu',\n",
       "  'validate_misc',\n",
       "  [['Sentence Id in the file: 42',\n",
       "    'Token Id: 7',\n",
       "    'Incorrect value found in misc 3'],\n",
       "   ['Sentence Id in the file: 173',\n",
       "    'Token Id: 4',\n",
       "    'Incorrect value found in misc 1'],\n",
       "   ['Sentence Id in the file: 243',\n",
       "    'Token Id: 7',\n",
       "    'Incorrect value found in misc 1'],\n",
       "   ['Sentence Id in the file: 315',\n",
       "    'Token Id: 9',\n",
       "    'Incorrect value found in misc 1'],\n",
       "   ['Sentence Id in the file: 367',\n",
       "    'Token Id: 13',\n",
       "    'Incorrect value found in misc 6'],\n",
       "   ['Sentence Id in the file: 470',\n",
       "    'Token Id: 6',\n",
       "    'Incorrect value found in misc 2'],\n",
       "   ['Sentence Id in the file: 615',\n",
       "    'Token Id: 6',\n",
       "    'Incorrect value found in misc 1']]],\n",
       " ['Phase1',\n",
       "  'hi_6441_gold.conllu',\n",
       "  'validate_misc',\n",
       "  [['Sentence Id in the file: 393',\n",
       "    'Token Id: 9',\n",
       "    'Incorrect value found in misc 4']]],\n",
       " ['Phase1',\n",
       "  'hi_6523_gold.conllu',\n",
       "  'validate_num_cols',\n",
       "  [['Sentence Id: 450', 'Token Id: 3', 'Number of columns: 9']]],\n",
       " ['Phase1',\n",
       "  'hi_6523_gold.conllu',\n",
       "  'validate_whitespaces',\n",
       "  [['Sentence Id: 450',\n",
       "    'Token Id: 3',\n",
       "    \"Whitespaces: [(' ', '\\\\tADV QF\\\\t')]\"]]],\n",
       " ['Phase1',\n",
       "  'hi_6523_gold.conllu',\n",
       "  'validate_punct',\n",
       "  [['Sentence Id in the file: 192',\n",
       "    'Token Id: 12',\n",
       "    'Head of PUNCT is 9 and not root token_id 4'],\n",
       "   ['Sentence Id in the file: 204',\n",
       "    'Token Id: 10',\n",
       "    'Head of PUNCT is 6 and not root token_id 3'],\n",
       "   ['Sentence Id in the file: 461',\n",
       "    'Token Id: 13',\n",
       "    'Head of PUNCT is 10 and not root token_id 4'],\n",
       "   ['Sentence Id in the file: 508', 'More than one punctuation upos found'],\n",
       "   ['Sentence Id in the file: 616',\n",
       "    'Token Id: 14',\n",
       "    'Head of PUNCT is 13 and not root token_id 11'],\n",
       "   ['Sentence Id in the file: 623',\n",
       "    'Token Id: 18',\n",
       "    'Head of PUNCT is 9 and not root token_id 4'],\n",
       "   ['Sentence Id in the file: 625',\n",
       "    'Token Id: 13',\n",
       "    'Head of PUNCT is 11 and not root token_id 4'],\n",
       "   ['Sentence Id in the file: 657',\n",
       "    'Token Id: 15',\n",
       "    'Head of PUNCT is 8 and not root token_id 3'],\n",
       "   ['Sentence Id in the file: 906',\n",
       "    'Token Id: 13',\n",
       "    'Head of PUNCT is 9 and not root token_id 4']]],\n",
       " ['Phase1',\n",
       "  'hi_6523_gold.conllu',\n",
       "  'validate_misc',\n",
       "  [['Sentence Id in the file: 39',\n",
       "    'Token Id: 8',\n",
       "    'Incorrect value found in misc 3'],\n",
       "   ['Sentence Id in the file: 57',\n",
       "    'Token Id: 8',\n",
       "    'Incorrect value found in misc 2'],\n",
       "   ['Sentence Id in the file: 167',\n",
       "    'Token Id: 6',\n",
       "    'Incorrect value found in misc 3'],\n",
       "   ['Sentence Id in the file: 190',\n",
       "    'Token Id: 10',\n",
       "    'Incorrect value found in misc 5'],\n",
       "   ['Sentence Id in the file: 206',\n",
       "    'Token Id: 8',\n",
       "    'Incorrect value found in misc 4'],\n",
       "   ['Sentence Id in the file: 256',\n",
       "    'Token Id: 11',\n",
       "    'Incorrect value found in misc 8'],\n",
       "   ['Sentence Id in the file: 298',\n",
       "    'Token Id: 8',\n",
       "    'Incorrect value found in misc 1'],\n",
       "   ['Sentence Id in the file: 357',\n",
       "    'Token Id: 9',\n",
       "    'Incorrect value found in misc 4'],\n",
       "   ['Sentence Id in the file: 386',\n",
       "    'Token Id: 9',\n",
       "    'Incorrect value found in misc 5'],\n",
       "   ['Sentence Id in the file: 936',\n",
       "    'Token Id: 7',\n",
       "    'Incorrect value found in misc 1'],\n",
       "   ['Sentence Id in the file: 996',\n",
       "    'Token Id: 14',\n",
       "    'Incorrect value found in misc 9'],\n",
       "   ['Sentence Id in the file: 1102',\n",
       "    'Token Id: 10',\n",
       "    'Incorrect value found in misc 4'],\n",
       "   ['Sentence Id in the file: 1111',\n",
       "    'Token Id: 1',\n",
       "    'Incorrect value found in misc 8']]],\n",
       " ['Phase1',\n",
       "  'hi_6579_gold.conllu',\n",
       "  'validate_misc',\n",
       "  [['Sentence Id in the file: 56',\n",
       "    'Token Id: 9',\n",
       "    'Incorrect value found in misc 1'],\n",
       "   ['Sentence Id in the file: 222',\n",
       "    'Token Id: 7',\n",
       "    'Incorrect value found in misc 4'],\n",
       "   ['Sentence Id in the file: 292',\n",
       "    'Token Id: 21',\n",
       "    'Incorrect value found in misc 17']]],\n",
       " ['Phase1',\n",
       "  'hi_6585_gold.conllu',\n",
       "  'validate_punct',\n",
       "  [['Sentence Id in the file: 434',\n",
       "    'Token Id: 8',\n",
       "    'Head of PUNCT is 3 and not root token_id 1']]],\n",
       " ['Phase1',\n",
       "  'hi_6585_gold.conllu',\n",
       "  'validate_misc',\n",
       "  [['Sentence Id in the file: 3',\n",
       "    'Token Id: 9',\n",
       "    'Incorrect value found in misc 2'],\n",
       "   ['Sentence Id in the file: 204',\n",
       "    'Token Id: 7',\n",
       "    'Incorrect value found in misc 5'],\n",
       "   ['Sentence Id in the file: 321',\n",
       "    'Token Id: 8',\n",
       "    'Incorrect value found in misc 3'],\n",
       "   ['Sentence Id in the file: 454',\n",
       "    'Token Id: 6',\n",
       "    'Incorrect value found in misc 1'],\n",
       "   ['Sentence Id in the file: 479',\n",
       "    'Token Id: 3',\n",
       "    'Incorrect value found in misc 1'],\n",
       "   ['Sentence Id in the file: 531',\n",
       "    'Token Id: 9',\n",
       "    'Incorrect value found in misc 7'],\n",
       "   ['Sentence Id in the file: 658',\n",
       "    'Token Id: 9',\n",
       "    'Incorrect value found in misc 4'],\n",
       "   ['Sentence Id in the file: 707',\n",
       "    'Token Id: 6',\n",
       "    'Incorrect value found in misc 1'],\n",
       "   ['Sentence Id in the file: 781',\n",
       "    'Token Id: 5',\n",
       "    'Incorrect value found in misc 2']]]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanity_checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690deccc-dd77-4193-ad95-ae0d914b6da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf905b75-cb35-4376-be2a-08c30bd3cab0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "737bd4df-9a1f-4e2b-8c14-3229c869dbf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sanity_checks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "59825d91-c1d7-49ed-b6da-ae077d525d88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.explode(3, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2925260a-89f5-4d71-9996-0181d9848a38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"sanity_checks_v2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acd9d10-12d4-44ad-bb9e-e9aee8c790be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b249f8ee-0b6d-4f96-b4ab-564208a9ba3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c058a09b-4505-4d88-8013-724495744a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452c722f-449a-4523-b180-2e69304f4ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eb733f-a07b-47b7-bf0a-41b671623a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c15294b-d394-4fd7-978b-a96b0b0f7626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c23314-65d3-4e3d-809a-89031f53119d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61738867-6c95-4a34-aca4-4616a96871bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013a63a9-f71c-4079-925a-243707daf6c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7525d6-5b02-401b-9032-53154d394e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66f06d6-305d-4c32-87f8-ebd61ad19686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d80796-2278-4bfe-9b79-346b9ef92866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a392f1-66fd-4f7d-a730-b006b4640f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fe46e5-83e6-438c-9580-7b431e3b1b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340f8ec1-1937-4ed3-8434-dfcf8d326e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47afa7b2-589e-46a7-b214-d867ca4a9ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c61ca13-4406-4994-9690-34c0157c4b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f2ef3d-7bfd-40d4-9420-35b29af7ca3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec500fc-9e48-4e39-a049-7da3351dbbcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc353347-c831-4591-97b1-1e35ab8e41a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9c22c3-9c99-4447-976e-72bec5c5d5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d483e9c-e518-4b50-954d-d90136a54578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72abdeb-3fd8-451d-83fc-282109dc6d51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cd6d14-502a-4144-a625-7d9d22e9236a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ee253f-9e8e-4015-b283-5ebfd2da7ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2623d6fa-b0dc-48a3-a902-e7b007de9b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac997687-b6b0-4456-a3d6-da5881c51e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a329c48-cc18-489d-8ee0-42fc77d9a14a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5341d504-2670-44d5-a550-39be07218f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fea9e51-a49d-4cd9-9964-ae09be7a7f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d4e9c5-64e0-4d92-a6ff-1cc86b1b93e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281cf7c2-c995-44d2-b6fc-03e2cf7743fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e07ae7-91ce-4d46-b92e-43ea018cc1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7045c6-c6b8-4781-a37c-c31f60cd6d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "cb7c405d-50a8-487a-a240-c655b9c23d93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sanity_check': 'validate_num_cols',\n",
       " 'phase': 'Phase1',\n",
       " 'file': 'hi_6523_gold.conllu',\n",
       " 'details': [[('Sentence Id: ', 450),\n",
       "   ('Token Id: ', '3'),\n",
       "   ('Number of columns: ', 9)]]}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c84f1b-253c-4ee2-9704-f15e7d6b34e4",
   "metadata": {},
   "source": [
    "## White spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ea7a2286-a0e7-4d1f-9a63-8e528a896600",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../parse_gold/Phase1/hi_1385_gold.conllu\n",
      "<bound method Token.conll of <pyconll.unit.token.Token object at 0x7f315a69b640>>\n",
      "<bound method Token.conll of <pyconll.unit.token.Token object at 0x7f315a69b240>>\n",
      "<bound method Token.conll of <pyconll.unit.token.Token object at 0x7f314ba5ab40>>\n",
      "<bound method Token.conll of <pyconll.unit.token.Token object at 0x7f314ba5a9c0>>\n",
      "<bound method Token.conll of <pyconll.unit.token.Token object at 0x7f314ba5acc0>>\n",
      "<bound method Token.conll of <pyconll.unit.token.Token object at 0x7f314ba5aa40>>\n",
      "<bound method Token.conll of <pyconll.unit.token.Token object at 0x7f314ba5ac40>>\n",
      "../../parse_gold/Phase1/hi_4370_gold.conllu\n",
      "<bound method Token.conll of <pyconll.unit.token.Token object at 0x7f315a9b8bc0>>\n",
      "<bound method Token.conll of <pyconll.unit.token.Token object at 0x7f315a9b8f40>>\n",
      "<bound method Token.conll of <pyconll.unit.token.Token object at 0x7f315a9b86c0>>\n",
      "<bound method Token.conll of <pyconll.unit.token.Token object at 0x7f315a9b8c40>>\n",
      "../../parse_gold/Phase1/hi_6322_gold.conllu\n",
      "<bound method Token.conll of <pyconll.unit.token.Token object at 0x7f315adcc540>>\n",
      "<bound method Token.conll of <pyconll.unit.token.Token object at 0x7f315a69b640>>\n",
      "../../parse_gold/Phase1/hi_6435_gold.conllu\n",
      "<bound method Token.conll of <pyconll.unit.token.Token object at 0x7f315a9b8f40>>\n",
      "<bound method Token.conll of <pyconll.unit.token.Token object at 0x7f315a9b86c0>>\n",
      "../../parse_gold/Phase1/hi_6441_gold.conllu\n",
      "<bound method Token.conll of <pyconll.unit.token.Token object at 0x7f315a69b240>>\n",
      "<bound method Token.conll of <pyconll.unit.token.Token object at 0x7f315a69bec0>>\n",
      "<bound method Token.conll of <pyconll.unit.token.Token object at 0x7f315a69bf40>>\n",
      "../../parse_gold/Phase1/hi_6523_gold.conllu\n",
      "The number of columns per token line must be 10. Invalid token: 3\tबहुत\tबहुत\tADV QF\tPronType=Ind\t4\tadvmod\t_\t_\n",
      "<bound method Token.conll of <pyconll.unit.token.Token object at 0x7f315a69b240>>\n",
      "<bound method Token.conll of <pyconll.unit.token.Token object at 0x7f315a69bec0>>\n",
      "<bound method Token.conll of <pyconll.unit.token.Token object at 0x7f315a69bf40>>\n",
      "../../parse_gold/Phase1/hi_6579_gold.conllu\n",
      "<bound method Token.conll of <pyconll.unit.token.Token object at 0x7f314b254940>>\n",
      "<bound method Token.conll of <pyconll.unit.token.Token object at 0x7f314b254ec0>>\n",
      "../../parse_gold/Phase1/hi_6585_gold.conllu\n",
      "<bound method Token.conll of <pyconll.unit.token.Token object at 0x7f314ba04c40>>\n",
      "<bound method Token.conll of <pyconll.unit.token.Token object at 0x7f314ba04bc0>>\n",
      "<bound method Token.conll of <pyconll.unit.token.Token object at 0x7f314ba048c0>>\n"
     ]
    }
   ],
   "source": [
    "invalid_files = []\n",
    "for phase in dirs:\n",
    "    if not os.path.isfile(os.path.join(filepath, phase)):    \n",
    "        # print(phase)\n",
    "        phase_path = os.path.join(filepath, phase)\n",
    "        output_files = sorted(os.listdir(phase_path))\n",
    "        # print(filepath, os.path.join(filepath, phase),output_files)\n",
    "        \n",
    "        for file in output_files:\n",
    "            output_file_path = os.path.join(phase_path, file)\n",
    "            print(output_file_path)\n",
    "            try:\n",
    "                output_file = pyconll.load_from_file(output_file_path)\n",
    "            except pyconll.exception.ParseError as e:\n",
    "                print(e)\n",
    "                invalid_files.append(output_file_path)\n",
    "#                 with open(output_file_path, 'r') as output_file:\n",
    "#                     for line in output_file:\n",
    "#                         # print(line)\n",
    "#                         if not line.startswith(\"#\") or line.strip() == \"\":\n",
    "                            \n",
    "#                             # if \" \" or \"  \" in line:\n",
    "#                             #     print(f\"Whitespace found at line {line} in {file}\")\n",
    "                            \n",
    "#                             count_cols = len(line.split('\\t'))\n",
    "#                             if count_cols!=10:\n",
    "#                                 # import pdb;pdb.set_trace()\n",
    "#                                 print(f\"Invalid number of columns at line {line} in {file}: {(count_cols)} columns found.\")\n",
    "                                \n",
    "            \n",
    "            for sentence in output_file:\n",
    "                \n",
    "                for token in sentence:\n",
    "                    # print(token.startswith(\"#\"))\n",
    "                    # if token.line.startswith('#'):\n",
    "                    print(token.conll)\n",
    "                    # print(re.match(r\"^\\s+$\", token.form))\n",
    "            \n",
    "            \n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45689be7-9d3c-415d-8fb9-24715acbf63f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ea76b27-ead9-4a3c-a31c-2631c9fdbf6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"../../DC_ph1_gold/hi_1385_gold.conllu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a02acc95-248e-48b1-a6c3-dee8eaf9e5f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_1385 = pyconll.load_from_file(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56505c05-50a0-4447-95ca-1d129d3c8259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55d30c8-6fba-4039-93b4-44d4c8ed9258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14761664-53cb-494d-86c2-25c7de766528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03609216-3b54-46bf-8e5e-5837e943907d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "13\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "18\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "9\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "#########\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "#########\n",
      "9\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "11\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "11\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "11\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "#########\n",
      "9\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "#########\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "#########\n",
      "13\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "12\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "19\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "14\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "17\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "12\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "9\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "12\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "9\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "16\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "9\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "12\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "13\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "9\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "9\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "14\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "12\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "11\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "9\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "11\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "12\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "12\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "13\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "#########\n",
      "9\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "11\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "13\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "12\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "25\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "13\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "#########\n",
      "18\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "9\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "11\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "11\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "15\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "11\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "12\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "16\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "19\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "11\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "13\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "13\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "14\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "#########\n",
      "11\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "11\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "#########\n",
      "11\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "12\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "9\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "11\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "12\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "17\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "9\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "#########\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "#########\n",
      "11\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "12\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "11\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "11\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "13\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "9\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "14\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "9\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "12\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "9\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "#########\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "#########\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n",
      "#########\n",
      "2\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for sentence in file_1385:\n",
    "    sentence_string = sentence.meta_value(\"Sentence\")\n",
    "    list_sent = sentence_string.split(\" \")\n",
    "    token_count = len(list_sent)\n",
    "    print(\"#########\")\n",
    "    print(token_count)\n",
    "    \n",
    "    for token in sentence:\n",
    "        print(token.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da8e765-985a-4b8f-8b95-3f834172c414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
