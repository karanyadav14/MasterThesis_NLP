{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d431dfd",
   "metadata": {
    "id": "8d431dfd",
    "outputId": "319a49cb-fb54-4f70-82fc-6c2d952dc98d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a deprel : Compound\n",
      "Enter a UPOS : adj\n",
      "\n",
      "Total number of instances matched are:  11\n",
      "\n",
      "List of Sentence Id, token Id and word form:  [('37', '5', 'पूरा'), ('37', '9', 'वापस'), ('54', '1', 'पागल'), ('79', '3', 'प्रपोज़ल'), ('81', '6', 'खतम'), ('172', '1', 'मालूम'), ('243', '6', 'बदनाम'), ('292', '3', 'बुड्ढ़ा'), ('355', '5', 'बदनाम'), ('500', '3', 'फ़ेल'), ('504', '7', 'फ़ेल')]\n",
      "\n",
      "List of corresponding governors and their UPOS:  [('घूम', 'VERB'), ('घूम', 'VERB'), ('हो', 'VERB'), ('हो', 'VERB'), ('करने', 'VERB'), ('कर', 'VERB'), ('कर', 'VERB'), ('हो', 'VERB'), ('करोगे', 'VERB'), ('करने', 'VERB'), ('हो', 'VERB')]\n",
      "\n",
      "List of Sentences:  ['मालूम नहीं कम्प्यूटर रिकॉर्ड कर रहा है ।', '[laughter] क्या प्रपोज़ल हो गया उस का ।', 'और सब का नाम बदनाम करोगे क्या ।', 'बोल रहा कि यूएस पूरा घूम के जाएगा वापस ।', 'ये तो बुड्ढ़ा हो गया होगा अब तो यार ।', '[laughter] तुम अपना नाम जितना बदनाम कर सकते हो कर लो ।', 'अम वैसे फ़ेल करने लायक थे भी नहीं ।', 'जिन्होंने मतलब 1 आद एग्ज़ैम में फ़ेल हो गया गॉट_बीज़ ।', 'अब तो थीसिस वीसिस मतलब खतम करने के मूड में है ।', 'पागल हो गया होगा वो ।']\n"
     ]
    }
   ],
   "source": [
    "## Searching certain features \n",
    "## This file at the moment help to search sentence based on individual search filters like nsubj or CC or AUX\n",
    "#Categories of search are [token.form, token.lemma, token.upos, token.xpos, token.head, token.deprel]\n",
    "\n",
    "\n",
    "import os\n",
    "import pyconll\n",
    "\n",
    "#giving the path of the directory\n",
    "path = \"E:/Cognitive_Science/Sem_III/HSD621_Masters_Project/DialogueCorpus/syntactic_analysis/SingleScript/\"\n",
    "dirs = os.listdir(path)\n",
    "\n",
    "# for every file in the directory\n",
    "for file in dirs:\n",
    "    filename = path+str(file)\n",
    "\n",
    "    if filename.endswith(\"hi_1385_output - Copy.txt\"):\n",
    "        filename_in = filename\n",
    "    \n",
    "        val1 = input('Enter a deprel : ').lower()\n",
    "        val2 = input('Enter a UPOS : ').upper()\n",
    "       \n",
    "        \n",
    "        file = pyconll.load_from_file(filename_in)\n",
    "        count = 0\n",
    "        sent_list=[]\n",
    "        sent_id_list = []\n",
    "        governors=[]\n",
    "        governor_pos=[]\n",
    "  \n",
    "        for sentence in file:\n",
    "            for token in sentence:\n",
    "\n",
    "                if (val1 in token.deprel) and (val2 in token.upos): \n",
    "                    governors.append(((sentence.meta_value('sent_id')),token.head))\n",
    "                    count+=1\n",
    "                    sent_id_list.append((sentence.meta_value('sent_id'), token.id, token.form))\n",
    "                    sent_list.append(sentence.meta_value('Sentence'))\n",
    "                \n",
    "                \n",
    "                    \n",
    "\n",
    "        for sentence in file:\n",
    "            for token in sentence:\n",
    "                \n",
    "                for sent_id, head in governors:\n",
    "                    if sent_id==sentence.meta_value('sent_id') and head in token.id:\n",
    "                        governor_pos.append((token.form,token.upos))\n",
    "                                    #(sentence.meta_value('Sentence')) \n",
    "\n",
    "                    \n",
    "#         print(\"\\n Number of Sentences in the file : \", count_sent)\n",
    "#         print(\"\\n Total Number of words in the file : \", count_word)\n",
    "#         print(\"\\n Total Number of words in the file excluding mentioned tokens: \", count_tags)\n",
    "\n",
    "        print(\"\\nTotal number of instances matched are: \", count)\n",
    "        \n",
    "        if count!=0:\n",
    "            \n",
    "            print(\"\\nList of Sentence Id, token Id and word form: \", sent_id_list)\n",
    "            print(\"\\nList of corresponding governors and their UPOS: \", governor_pos)\n",
    "            print(\"\\nList of Sentences: \", list(set(sent_list)))\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "                      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fe8561",
   "metadata": {
    "id": "b3fe8561",
    "outputId": "f902e096-3f52-4414-ff27-e6b4414d963c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter misc annotation tag: Repair\n",
      "('17', '2', 'तो_ये_इस_वक्त_आइ_मीन_अ_ये')\n",
      "('17', '5', 'इंडी')\n",
      "('20', '1', 'हील')\n",
      "('28', '1', 'आ_के')\n",
      "('48', '1', 'सब')\n",
      "('49', '1', 'सब_जगह_जाना')\n",
      "('49', '2', 'सब_से')\n",
      "('55', '1', 'रेंटल')\n",
      "('70', '1', 'ढ़ूँढ_के_र')\n",
      "('121', '1', 'दैट')\n",
      "('125', '1', {\"'एसिक्स_लाइब्रेरी'\"})\n",
      "('129', '1', 'ये_सब')\n",
      "('151', '1', {\"'हाउ_मेनी'\"})\n",
      "('169', '5', 'विक')\n",
      "('179', '1', 'ह')\n",
      "('226', '1', {\"'आइ'\"})\n",
      "('248', '1', 'आर_यू_आर_यू')\n",
      "('261', '2', 'तुम्हारा_दुश')\n",
      "('283', '3', {\"'आइ_डोंट'\"})\n",
      "('287', '1', {\"'आइ_मीन_शीस'\"})\n",
      "('296', '1', 'तेत')\n",
      "('314', '2', 'और_मैं_क्या')\n",
      "('314', '3', 'और_एनिवन')\n",
      "('340', '4', 'ये_तो')\n",
      "('354', '3', 'कौ')\n",
      "('372', '2', 'क्या')\n",
      "('386', '1', 'कार')\n",
      "('395', '3', 'मतलब_डिड')\n",
      "('416', '1', 'हाँ_लेकिन_यहाँ_मतलब_।')\n",
      "('417', '1', 'अह_ओह_आइम_श्योर_ही_वुड_गो_टू_बॉस्टन_ऑल्सो_ड्राइविंग_।')\n",
      "('419', '1', 'मैं')\n",
      "('420', '5', 'उस_का')\n",
      "('422', '2', 'काफ़ी_लम_बहुत')\n",
      "('428', '4', 'हो_गया_है')\n",
      "('429', '4', 'ड्य')\n",
      "('457', '1', 'उस')\n",
      "('494', '1', 'मतलब_फ़ाइनल_कोर')\n",
      "('497', '1', 'कितने')\n",
      "('501', '1', 'कुछ')\n",
      "('512', '1', {\"'एमएस_और_पीएचडी'\"})\n",
      "('515', '1', 'तो_कोई')\n",
      "('515', '2', {\"'ऐज़'\"})\n",
      "('524', '1', 'ब_2_घंटा')\n",
      "('555', '5', '1_कॉर्नेल')\n"
     ]
    }
   ],
   "source": [
    "# Misc Column\n",
    "\n",
    "import os\n",
    "import pyconll\n",
    "\n",
    "#giving the path of the directory\n",
    "path = \"E:/Cognitive_Science/Sem_III/HSD621_Masters_Project/DialogueCorpus/syntactic_analysis/SingleScript/\"\n",
    "dirs = os.listdir(path)\n",
    "\n",
    "# for every file in the directory\n",
    "for file in dirs:\n",
    "    filename = path+str(file)\n",
    "\n",
    "    if filename.endswith(\"_output - Copy.txt\"):\n",
    "        filename_in = filename\n",
    "\n",
    "        file = pyconll.load_from_file(filename_in)\n",
    "\n",
    "        val3 = input('Enter misc annotation tag: ')\n",
    "        \n",
    "        for sentence in file:\n",
    "            for token in sentence:\n",
    "                \n",
    "                if token.head=='root' and token.upos=='INTJ':\n",
    "                    print(\"Root with INTJ tag: \", (sentence.meta_value('sent_id')))\n",
    "   \n",
    "\n",
    "                \n",
    "                if val3 in token.misc.keys():\n",
    "#                     print(token.misc)\n",
    "                    if token.misc[val3]=={'Matrix_Tag'}:\n",
    "                        print((sentence.meta_value('sent_id'),token.id, token.form))\n",
    "                    else:\n",
    "                        print((sentence.meta_value('sent_id'),token.id, token.misc[val3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94a6aa6",
   "metadata": {
    "id": "b94a6aa6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ada36b4",
   "metadata": {
    "id": "8ada36b4",
    "outputId": "acca60c9-655d-4161-b4b4-0b3c09b7d223"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Phase', 'Filename', 'Duration', 'No.of_Speakers', 'No.of_Sentences', 'No.of_Tokens(all)', 'No.of_Repair', 'No.of_Disfluency', 'No.of_Code-switching', 'No.of_OtherTags', 'No.of_Tokens(w/o chunks&OtherTags)'], [1, 'hi_1385_output.txt', '00:14:58.350', 2, 561, 2887, 44, 17, 99, 64, 2663], [1, 'hi_4370_output.txt', '00:15:37.090', 3, 577, 3226, 52, 11, 35, 103, 3025], [1, 'hi_6322_output.txt', '00:19:37.581', 2, 732, 3835, 29, 4, 0, 96, 3706], [1, 'hi_6435_output.txt', '00:22:57.686', 2, 974, 5589, 45, 10, 5, 165, 5364], [1, 'hi_6441_output.txt', '00:24:42.934', 2, 708, 3654, 29, 9, 26, 23, 3543], [1, 'hi_6523_output.txt', '00:26:47.527', 2, 1167, 7563, 81, 10, 47, 103, 7321], [1, 'hi_6579_output.txt', '00:14:03.110', 2, 620, 3259, 53, 38, 111, 34, 3023], [1, 'hi_6585_output.txt', '00:26:07.076', 2, 1021, 5021, 71, 25, 242, 73, 4610], [1, 'Stat.csv', '00:26:07.076', 2, 1021, 5021, 71, 25, 242, 73, 4610]]\n"
     ]
    }
   ],
   "source": [
    "## Number of Sentences, words in the file\n",
    "\n",
    "\n",
    "import os\n",
    "import pyconll\n",
    "import csv\n",
    "\n",
    "\n",
    "#giving the path of the directory\n",
    "path = \"E:/Cognitive_Science/Project/DialogueCorpus/syntactic_analysis/SingleScript/Output_files/\"\n",
    "dirs = os.listdir(path)\n",
    "\n",
    "result_list = []    \n",
    "\n",
    "Total_sent = 0\n",
    "Total_words=0\n",
    "Total_words_tags = 0\n",
    "Total_time=0\n",
    "Phase = 1\n",
    "\n",
    "title = ['Phase','Filename','Duration','No.of_Speakers','No.of_Sentences','No.of_Tokens(all)','No.of_Repair','No.of_Disfluency',\n",
    "                 'No.of_Code-switching','No.of_OtherTags','No.of_Tokens(w/o chunks&OtherTags)']\n",
    "result_list.append(title)\n",
    "\n",
    "# for every file in the directory\n",
    "for file in dirs:\n",
    "    filename = path+str(file)\n",
    "     \n",
    "\n",
    "    \n",
    "    if filename.endswith(\"_output.txt\"):\n",
    "        filename_in = filename\n",
    "        filename_out = filename_in.replace(\"_output.txt\",\"_Stat.csv\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        file1 = pyconll.load_from_file(filename_in)\n",
    "\n",
    "\n",
    "        count_sent = 0\n",
    "        count_word = 0\n",
    "        count_tags = 0\n",
    "        list_form= [\"[laughter]\", \"[noise]\", \"[incomprehensible]\", \"[pause]\",\"[aside]\"]\n",
    "        list_form_count=0\n",
    "        count_repair = 0\n",
    "        count_disfluency = 0\n",
    "        count_codeswitch = 0\n",
    "        count_quote = 0\n",
    "#         list_misc = ['Hesitation', 'Disfluency','Repair']\n",
    "        list_misc_count=0\n",
    "        misc_keys = []\n",
    "\n",
    "        for sentence in file1:\n",
    "            count_sent+=1\n",
    "            for token in sentence:\n",
    "                count_word+=1\n",
    "#                 print(token.misc.keys())\n",
    "#                 if token.form in list_form:\n",
    "#                     print(token.misc)\n",
    "\n",
    "                if token.form in list_form:\n",
    "#                     print(token.form)\n",
    "                    list_form_count+=1\n",
    "\n",
    "                \n",
    "#                 print(token.misc.keys())\n",
    "                for i in token.misc.keys():\n",
    "                    if i=='Repair':\n",
    "                        count_repair+=1\n",
    "                    if i =='Disfluency':\n",
    "                        count_disfluency+=1\n",
    "                    \n",
    "                    if i =='CodeSwitch':\n",
    "                        count_codeswitch+=1\n",
    "                        \n",
    "                    if i =='Quote':\n",
    "                        count_quote+=1\n",
    "                    \n",
    "#                         print(\"##\")\n",
    "#                         list_misc_count+=1\n",
    "\n",
    "        sum_tags = list_form_count+list_misc_count\n",
    "\n",
    "        end_time=0\n",
    "        speakers= []\n",
    "        \n",
    "        for sentence in file1:\n",
    "            speakers.append(sentence.meta_value('speaker_id'))\n",
    "            \n",
    "            if(sentence.meta_value('sent_id')==str(count_sent)):\n",
    "                end_time = (sentence.meta_value('end_time'))           \n",
    "                t = end_time.split(':')\n",
    "                total_min =int(t[1])\n",
    "            \n",
    "                if(float(t[2])>30.0):\n",
    "                    total_min+=1\n",
    " \n",
    "                            \n",
    "        speakers = list(set(speakers))\n",
    "        #print(len(speakers))\n",
    "\n",
    "    Total_sent += count_sent\n",
    "    Total_words+= count_word\n",
    "    Total_words_tags += count_word-sum_tags\n",
    "    Total_time +=total_min\n",
    "    \n",
    "    \n",
    "#     print(\"list_form_count\", list_form_count)\n",
    "    total_chunks = count_repair + count_disfluency + count_codeswitch + count_quote\n",
    "#     print(\"total_chunks: \", total_chunks)\n",
    "    \n",
    "    tokens_without_tags = count_word - total_chunks - list_form_count\n",
    "    \n",
    "    result_list.append([Phase,file,end_time,len(speakers),count_sent,count_word,count_repair,count_disfluency,count_codeswitch,\n",
    "                       list_form_count,tokens_without_tags])\n",
    "    \n",
    "# print(result_list)            \n",
    "\n",
    "\n",
    "try:\n",
    "    file_out = path+\"Stat.csv\"\n",
    "    with open(file_out, \"w\",encoding=\"utf-8\", newline='',) as csvfile:\n",
    "        # creating a csv writer object\n",
    "        csvwriter = csv.writer(csvfile, delimiter = ',')\n",
    "        csvwriter.writerows(result_list)\n",
    "except OSError as error:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0708cebe",
   "metadata": {
    "id": "0708cebe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46777bf",
   "metadata": {
    "id": "d46777bf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Search_Document.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
