{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "772aaeb2",
   "metadata": {
    "id": "772aaeb2"
   },
   "source": [
    "## Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb5b07cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "error",
     "timestamp": 1683973420409,
     "user": {
      "displayName": "Karan Yadav",
      "userId": "16084954556777141985"
     },
     "user_tz": -330
    },
    "id": "cb5b07cd",
    "outputId": "93644fdd-4403-43b1-ec27-26c5caa1036b"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3050075626e1>\u001b[0m in \u001b[0;36m<cell line: 123>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0mcsvwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m \u001b[0mchecks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-3050075626e1>\u001b[0m in \u001b[0;36mchecks\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mchecks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# for every file in the directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'E:/Cognitive_Science/Sem_III/HSD621_Masters_Project/syntactic_analysis/single_script/'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "path1 = \"E:/Cognitive_Science/Sem_III/HSD621_Masters_Project/syntactic_analysis/single_script/\"\n",
    "\n",
    "def checks(file_path):\n",
    "    \n",
    "    dirs = os.listdir(file_path)\n",
    "\n",
    "    # for every file in the directory\n",
    "    for file in dirs:\n",
    "        filename = file_path+str(file)\n",
    "\n",
    "        if filename.endswith(\"_0.csv\"):\n",
    "            filename_in = filename\n",
    "            filename_out = filename_in.replace(\"_0.csv\", \"_ss_0checks.txt\")\n",
    "            #print (\"in = \"+ filename_in)\n",
    "            #print (\"out = \"+ filename_out)\n",
    "\n",
    "            fields = []\n",
    "            rows = []\n",
    "            column_value = \"\" #variable for the string in the transcription column\n",
    "            data_value= \"\" #variable for the string in the transcription column as it will appear in the output file\n",
    "            speaker_value = \"\" #variable for th string value of Speaker1 or Speaker2\n",
    "            result_list = []\n",
    "\n",
    "            count_overlap_sp1 = 0\n",
    "            count_overlap_sp2 = 0\n",
    "\n",
    "            with open(filename_in, 'r', encoding=\"utf-8\") as csvfile:\n",
    "                csvreader = csv.reader(csvfile)\n",
    "                reader = csv.DictReader(csvfile, delimiter=\",\")\n",
    "                #print (filename_in)\n",
    "\n",
    "                for row in reader:\n",
    "\n",
    "                    begin_time = row[\"Begin Time - hh:mm:ss.ms\"]\n",
    "                    end_time = row[\"End Time - hh:mm:ss.ms\"]\n",
    "                    duration = row[\"Duration - hh:mm:ss.ms\"]\n",
    "                    speaker_1 = row[\"Channel1\"]\n",
    "                    speaker_2 = row[\"Channel2\"]\n",
    "\n",
    "\n",
    "                    # the last above line assigns str in \"data\" column to variable data_value. \n",
    "                    # Also replaces a double white space with a single white space \n",
    "                    # Replaces pipe symbol with hindi purnaviram symbol\n",
    "                    if speaker_1 !=\"\":\n",
    "                        data_value=speaker_1;\n",
    "                    else:\n",
    "                        data_value=speaker_2;\n",
    "\n",
    "                    data_value = str(data_value).replace(\"  \",\" \").replace(\"|\",\"ред\")\n",
    "                    #count the number of \\d in the utterance and print (filename+begin_time_utterance) if odd number of occurances\n",
    "                    count_d = int(data_value.count(r\"\\d\"))\n",
    "                    if (count_d % 2) != 0:   \n",
    "                        print (\"ERROR FOR d: \" + filename_in[-16:-9] + \" \" + begin_time + \" \" + data_value)\n",
    "\n",
    "                    #count the number of \\r in the utterance and print (filename+begin_time_utterance) if odd number of occurances\n",
    "                    count_r = int(data_value.count(r\"\\r\"))\n",
    "                    if (count_r % 2) != 0:   \n",
    "                        print (\"ERROR FOR r: \" + filename_in[-16:-9] + \" \" + begin_time + \" \" + data_value)\n",
    "\n",
    "                    #count the number of \\h in the utterance and print (filename+begin_time_utterance) if odd number of occurances\n",
    "                    count_h = int(data_value.count(r\"\\h\"))\n",
    "                    if (count_h % 2) != 0:   \n",
    "                        print (\"ERROR FOR h: \" + filename_in[-16:-9] + \" \" + begin_time + \" \" + data_value)\n",
    "\n",
    "                    #count the number of \\exp in the utterance and print (filename+begin_time_utterance) if odd number of occurances\n",
    "                    count_exp = int(data_value.count(r\"\\exp\"))\n",
    "                    if (count_exp % 2) != 0:   \n",
    "                        print (\"ERROR FOR exp: \" + filename_in[-16:-9] + \" \" + begin_time + \" \" + data_value)\n",
    "\n",
    "                    #count the number of \\q in the utterance and print (filename+begin_time_utterance) if odd number of occurances\n",
    "                    count_q = int(data_value.count(r\"\\q\"))\n",
    "                    if (count_q % 2) != 0:   \n",
    "                        print (\"ERROR FOR q: \" + filename_in[-16:-9] + \" \" + begin_time + \" \" + data_value)\n",
    "\n",
    "                    #count the number of \\c in the utterance and print (filename+begin_time_utterance) if odd number of occurances\n",
    "                    count_c = int(data_value.count(r\"\\c\"))\n",
    "                    if (count_c % 2) != 0:   \n",
    "                        print (\"ERROR FOR c: \" + filename_in[-16:-9] + \" \" + begin_time + \" \" + data_value)\n",
    "\n",
    "                    #count the number of # in the utterance and print (filename+begin_time_utterance) if odd number of occurances\n",
    "                    count_overlap = int(data_value.count(r\"#\"))\n",
    "                    if (count_overlap % 2) != 0:   \n",
    "                        print (\"ERROR FOR overlap: \" + filename_in[-16:-9] + \" \" + begin_time + \" \" + data_value)\n",
    "\n",
    "                    #to check overlaps - additional check - for the 2 speakers, the total number of overlap tags should be the same\n",
    "                    if speaker_1 != \"\":\n",
    "                        count_overlap_sp1 = count_overlap_sp1 + count_overlap\n",
    "                    if speaker_2 != \"\":\n",
    "                        count_overlap_sp2 = count_overlap_sp2 + count_overlap\n",
    "\n",
    "                    if speaker_1 !=\"\":\n",
    "                        speaker_1=data_value;\n",
    "                    else:\n",
    "                        speaker_2=data_value;\n",
    "\n",
    "                    result_list.append([begin_time, end_time, duration, speaker_1, speaker_2])\n",
    "                    #print(result_list)\n",
    "\n",
    "            #the following prints for each file, the total number of overlap tags for Sp1 and Sp2 \n",
    "            print (str(filename_in[-20:-13]) + \" Sp1 overlap count is \" + str(int(count_overlap_sp1)))\n",
    "            print (str(filename_in[-20:-13]) + \" Sp2 overlap count is \" + str(int(count_overlap_sp2)))\n",
    "\n",
    "                # writing to csv file\n",
    "            directory=\"temp\"\n",
    "            new_path=os.path.join(file_path,directory)\n",
    "            print(new_path)\n",
    "            try:\n",
    "                os.makedirs(new_path,exist_ok=True)\n",
    "            except OSError as error:\n",
    "                pass\n",
    "                \n",
    "            with open(filename_out, 'w',encoding=\"utf-8\", newline='') as csvfile:\n",
    "                # creating a csv writer object\n",
    "                csvwriter = csv.writer(csvfile)\n",
    "                # writing the fields\n",
    "                fields = [\"Begin Time - hh:mm:ss.ms\",\"End Time - hh:mm:ss.ms\",\"Duration - hh:mm:ss.ms\", 'Channel1','Channel2']\n",
    "                csvwriter.writerow(fields)\n",
    "                csvwriter.writerows(result_list)\n",
    "\n",
    "checks(path1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8023dcf",
   "metadata": {
    "id": "a8023dcf"
   },
   "source": [
    "## Single_Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bc601c",
   "metadata": {
    "id": "96bc601c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import requests\n",
    "import pyconll\n",
    "\n",
    "class Parser:\n",
    "    \n",
    "    def __init__(self, filepath, parser_url):\n",
    "        self.filepath = filepath\n",
    "        self.parser_url= parser_url\n",
    "        \n",
    "    def format1(self):\n",
    "        \n",
    "        dirs = os.listdir(self.filepath)\n",
    "        #print(dirs)\n",
    "        for file in dirs:\n",
    "            filename = self.filepath+str(file)\n",
    "            \n",
    "            if filename.endswith(\"_ss_0checks.txt\"):\n",
    "                filename_in = filename\n",
    "                filename_out = filename_in.replace(\"_ss_0checks.txt\",\"_ss_1format.txt\")\n",
    "                #print (\"in = \"+ filename_in)\n",
    "                #print (\"out = \"+ filename_out)\n",
    "\n",
    "                fields = []\n",
    "                rows = []\n",
    "                column_value = \"\" #variable for the string in the transcription column\n",
    "                data_value= \"\" #variable for the string in the transcription column as it will appear in the output file\n",
    "                speaker_value = \"\" #variable for th string value of Speaker1 or Speaker2\n",
    "                result_list = []  \n",
    "\n",
    "                with open(filename_in, 'r', encoding=\"utf-8\") as csvfile:\n",
    "                    csvreader = csv.reader(csvfile)\n",
    "                    reader = csv.DictReader(csvfile, delimiter=\",\")\n",
    "                    #print (filename_in)\n",
    "                    \n",
    "                    flag=False\n",
    "                    flag1=False\n",
    "                    \n",
    "                    for row in reader:\n",
    "\n",
    "                        begin_time = row[\"Begin Time - hh:mm:ss.ms\"]\n",
    "                        end_time = row[\"End Time - hh:mm:ss.ms\"]\n",
    "                        duration = row[\"Duration - hh:mm:ss.ms\"]\n",
    "                        speaker_1 = row[\"Channel1\"]\n",
    "                        speaker_2 = row[\"Channel2\"]\n",
    "                        #print(speaker_1, len(speaker_1), \"-\", speaker_2, len(speaker_2))\n",
    "                        if len(str(speaker_1).strip()) == 0:    # use strip in case there are empty spaces at the end of the string\n",
    "                            column_value = str(speaker_2).strip()    #if empty then this col will be filled with speaker2 value \n",
    "                            if \"[b_speaker3]\" in (column_value):\n",
    "                                flag=True\n",
    "                                speaker_value=\"Sp3\"\n",
    "\n",
    "                            elif \"[e_speaker3]\" in (column_value) :\n",
    "                                flag=False\n",
    "                                speaker_value=\"Sp3\"\n",
    "\n",
    "                            elif flag==True:\n",
    "                                speaker_value=\"Sp3\"\n",
    "                            else:\n",
    "                                speaker_value = \"Sp2\"       # correct speaker id is inserted\n",
    "                        if len(str(speaker_2).strip()) == 0:\n",
    "                            column_value = str(speaker_1).strip()\n",
    "                            if \"[b_speaker3]\" in (column_value):\n",
    "                                flag1=True\n",
    "                                speaker_value=\"Sp3\"\n",
    "                            elif flag1==True:\n",
    "                                speaker_value=\"Sp3\"\n",
    "                            elif \"[e_speaker3]\" in (column_value) :\n",
    "                                flag1=False\n",
    "                                speaker_value=\"Sp3\"   \n",
    "                            else:\n",
    "                                speaker_value = \"Sp1\"\n",
    "                        data_value = column_value+str(\" ред\")     #add a period marker at the end of every utterance\n",
    "                        #This last above step can be omitted if the sentence segmentation is taken care of in the transcription\n",
    "                        result_list.append([begin_time, end_time, duration, speaker_value, data_value])\n",
    "                        #print(result_list)\n",
    "\n",
    "                # writing to csv file\n",
    "                with open(filename_out, 'w',encoding=\"utf-8\", newline='') as csvfile:\n",
    "                # creating a csv writer object\n",
    "                    csvwriter = csv.writer(csvfile)\n",
    "                # writing the fields\n",
    "                    fields = ['Begin_Time-hh:mm:ss.ms', 'End_Time-hh:mm:ss.ms', 'Duration-hh:mm:ss.ms', 'speaker_id', 'data']\n",
    "                    csvwriter.writerow(fields)\n",
    "                    csvwriter.writerows(result_list)\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "    def segment(self):\n",
    "        \n",
    "        \n",
    "        dirs = os.listdir(self.filepath)\n",
    "        #print(dirs)\n",
    "        for file in dirs:\n",
    "            filename = self.filepath+str(file)\n",
    "            \n",
    "            if filename.endswith(\"_ss_1format.txt\"):\n",
    "                filename_in = filename\n",
    "                filename_out = filename_in.replace(\"_ss_1format.txt\", \"_ss_2segment.txt\")\n",
    "                #print (\"in = \"+ filename_in)\n",
    "                #print (\"out = \"+ filename_out)\n",
    "\n",
    "                fields = []\n",
    "                rows = []\n",
    "                result_list = []\n",
    "                sent_id = 1\n",
    "\n",
    "                with open(filename_in, 'r',encoding=\"utf-8\") as csvfile:\n",
    "                    csvreader = csv.reader(csvfile)\n",
    "                    reader = csv.DictReader(csvfile, delimiter=',')\n",
    "\n",
    "                    result_list.append([(\"# sent_id = \" + str(sent_id)),\"\"])\n",
    "\n",
    "                    for row in reader:\n",
    "                        word_index = 1\n",
    "                        file_name= filename_in[-16:-9]\n",
    "                        begin_time = row[\"Begin_Time-hh:mm:ss.ms\"]\n",
    "                        end_time = row[\"End_Time-hh:mm:ss.ms\"]\n",
    "                        duration = row[\"Duration-hh:mm:ss.ms\"]\n",
    "                        speaker_name = row[\"speaker_id\"]\n",
    "                        rowdata = str(row['data']).strip()\n",
    "                        word_list = rowdata.split(' ')\n",
    "                        overlap_value = rowdata.find(\"#\")\n",
    "                        if overlap_value == -1:\n",
    "                            ol = \"False\"\n",
    "                        else: \n",
    "                            ol = \"True\"\n",
    "\n",
    "                        #print (word_list)\n",
    "\n",
    "                        result_list.append([(\"# begin_time = \" + str(begin_time)), \"\"])\n",
    "                        result_list.append([(\"# end_time = \" + str(end_time)), \"\"])\n",
    "                        result_list.append([(\"# duration = \" + str(duration)), \"\"])\n",
    "                        result_list.append([(\"# speaker_id = \" + str(speaker_name)), \"\"])\n",
    "                        result_list.append([(\"# contains_overlap = \"+ol), \"\"])\n",
    "\n",
    "                        i = 0\n",
    "                        N = len(word_list)\n",
    "\n",
    "                        for word in word_list:\n",
    "                            i = i + 1\n",
    "\n",
    "                            #if word != \"\": #this line creates a check for double spaces - not required now, as double speces eliminated by checks.py\n",
    "                            if word == \"#\":\n",
    "                                continue\n",
    "\n",
    "                            if word == \"ред\" and i < N:\n",
    "                                result_list.append([word_index, word])\n",
    "                                result_list.append([\"\", \"\"])\n",
    "\n",
    "                                word_index = 1\n",
    "                                sent_id = sent_id+1        \n",
    "                                result_list.append([(\"# sent_id = \" + str(sent_id)),\"\"])\n",
    "\n",
    "                                result_list.append([(\"# begin_time = \" + str(begin_time)),\"\"])\n",
    "                                result_list.append([(\"# end_time = \" + str(end_time)),\"\"])\n",
    "                                result_list.append([(\"# duration = \" + str(duration)),\"\"])\n",
    "                                result_list.append([(\"# speaker_id = \" + str(speaker_name)),\"\"])\n",
    "                                result_list.append([(\"# contains_overlap = \"+ol), \"\"])\n",
    "                            elif word == \"ред\":\n",
    "                                result_list.append([word_index, word])\n",
    "                                result_list.append([\"\", \"\"])\n",
    "\n",
    "                                word_index = 1\n",
    "                                sent_id = sent_id+1        \n",
    "                                result_list.append([(\"# sent_id = \" + str(sent_id)),\"\"])\n",
    "                            else:\n",
    "                                result_list.append([word_index, word])\n",
    "                                word_index = word_index+1\n",
    "\n",
    "\n",
    "                with open(filename_out, 'w',encoding=\"utf-8\", newline='') as csvfile:\n",
    "                    # creating a csv writer object\n",
    "                    csvwriter = csv.writer(csvfile, delimiter = '\\t')\n",
    "                    csvwriter.writerows(result_list)\n",
    "        \n",
    "\n",
    "    def chunks(self):\n",
    "        \n",
    "        dirs = os.listdir(self.filepath)\n",
    "        #print(dirs)\n",
    "        for file in dirs:\n",
    "            filename = self.filepath+str(file)\n",
    "        \n",
    "            if filename.endswith(\"_ss_2segment.txt\"):\n",
    "                filename_in = filename\n",
    "                filename_out = filename_in.replace(\"_ss_2segment.txt\", \"_ss_3chunks.txt\")\n",
    "                #print (\"in = \"+ filename_in)\n",
    "                #print (\"out = \"+ filename_out)\n",
    "\n",
    "                result_list= []\n",
    "                sent_id = 1\n",
    "                chunk_list = []\n",
    "                chunk = \"\"\n",
    "                chunk_id = \"\"\n",
    "                word_index = 1\n",
    "                misc = \"\"\n",
    "                with open(filename_in,'r', encoding = 'utf-8') as csvfile:\n",
    "                    csvreader = csv.reader(csvfile, delimiter='\\t')\n",
    "\n",
    "                    for row in csvreader:  \n",
    "                        word_n = row[0]\n",
    "                        #print(word_n)\n",
    "                        word_form = row[1]\n",
    "                        #print(word_form)\n",
    "                        #print(type(word_form))\n",
    "                        if len(chunk_list) != 0 and word_form[0]!=\"\\\\\":\n",
    "                            chunk_list.append(word_form)\n",
    "\n",
    "                        if word_n.startswith(\"#\"):\n",
    "                            result_list.append([word_n,\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"])\n",
    "                            continue\n",
    "                        elif word_n == \"\":\n",
    "                            continue \n",
    "                        elif word_form ==\"ред\":\n",
    "                            if len(chunk_list) != 0:\n",
    "                                chunk_list.append(chunk_id)\n",
    "                                chunk = \"_\".join(chunk_list)\n",
    "                                #chunk = chunk.replace(\"\\\\\",\"\")\n",
    "                                result_list.append([str(word_index),chunk,misc])\n",
    "                                word_index = word_index + 1\n",
    "                                result_list.append([str(word_index),word_form,\"_\"])\n",
    "                                result_list.append([\"\",\"\",\"\"])\n",
    "                                word_index = 1\n",
    "                                chunk_list =[]  \n",
    "                                #this block should check instances of errors where tag is not closed. This code should serve as a barrier for the error to carry over beyond sentence boundary.\n",
    "                                #check in the end if this block works, by manually removing one of the closing tags (outermost, not nested) in a sentence\n",
    "                            else:\n",
    "                                result_list.append([str(word_index),word_form,\"_\"])\n",
    "                                result_list.append([\"\",\"\",\"\"])\n",
    "                                word_index = 1  \n",
    "\n",
    "                        elif word_form.startswith(\"\\\\\"):\n",
    "                            if len(chunk_list) == 0:\n",
    "                                chunk_id = word_form\n",
    "                                chunk_list.append(word_form)\n",
    "                                \n",
    "                                 \n",
    "                                if word_form[1]=='q':\n",
    "                                    misc = \"Quote=Matrix_Tag\"\n",
    "                                if word_form[1]=='c': \n",
    "                                    misc = \"CodeSwitch=Matrix_Tag\"\n",
    "                                if word_form[1]=='r':\n",
    "                                    misc = \"Repair=Matrix_Tag\"\n",
    "                                if word_form[1]=='d':\n",
    "                                    misc = \"Disfluency=Matrix_Tag\"\n",
    "                                if word_form[1]=='h':\n",
    "                                    misc = \"Hesitation=Matrix_Tag\"\n",
    "                                if word_form[1]=='exp':  \n",
    "                                    misc = \"Expletive=Matrix_Tag\"\n",
    "\n",
    "                                #misc = word_form[1]+\"=Matrix_Tag\"  #As a dictionary item?\n",
    "                                #print(misc)\n",
    "                            elif word_form == chunk_id:\n",
    "                                chunk_list.append(word_form)\n",
    "                                chunk = \"_\".join(chunk_list)\n",
    "                                #chunk = chunk.replace(\"\\\\\",\"\")\n",
    "                                result_list.append([str(word_index),chunk,misc])\n",
    "                                word_index = word_index +1\n",
    "                                chunk_list =[]\n",
    "                            else:\n",
    "                                chunk_list.append(word_form)\n",
    "                            continue                            \n",
    "\n",
    "                        else:\n",
    "                            if len(chunk_list) == 0:\n",
    "                                result_list.append([str(word_index) ,word_form,\"_\"])\n",
    "                                word_index = word_index + 1\n",
    "\n",
    "                with open(filename_out, 'w',encoding = 'utf-8', newline='') as csvfile:\n",
    "                    csvwriter = csv.writer(csvfile, delimiter = '\\t')\n",
    "                    csvwriter.writerows(result_list)\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "    def misc(self):\n",
    "        \n",
    "        \n",
    "        dirs = os.listdir(self.filepath)\n",
    "        #print(dirs)\n",
    "        for file in dirs:\n",
    "            filename = self.filepath+str(file)\n",
    "        \n",
    "            if filename.endswith(\"_ss_3chunks.txt\"):\n",
    "                filename_in = filename\n",
    "                filename_out = filename_in.replace(\"_ss_3chunks.txt\", \"_ss_4misc.txt\")\n",
    "                #print (\"in = \"+ filename_in)\n",
    "                #print (\"out = \"+ filename_out)\n",
    "\n",
    "               \n",
    "                with open(filename_in,'r', encoding = 'utf-8') as csvfile:\n",
    "                    csvreader = csv.reader(csvfile, delimiter='\\t' )\n",
    "\n",
    "                    result_list = []\n",
    "\n",
    "                    for row in csvreader: \n",
    "                        \n",
    "\n",
    "                        word_n = row[0]\n",
    "                        word_form = row[1]\n",
    "                        misc = row[2]\n",
    "                        misc_list= []\n",
    "\n",
    "                        if word_n.startswith(\"#\"):\n",
    "                            result_list.append(word_n+'\\n')\n",
    "                            continue\n",
    "\n",
    "                        elif word_n ==\"\":\n",
    "                            result_list.append('\\n')  \n",
    "                            continue\n",
    "\n",
    "                        elif word_form.startswith(\"\\\\\"):\n",
    "                            misc_list.append(misc)\n",
    "                            if \"_\\\\q_\" in word_form or \"_\\\\r_\" in word_form or \"_\\\\d_\" in word_form or \"_\\\\h_\" in word_form or \"_\\\\c_\" in word_form or \"_\\\\exp_\" in word_form:\n",
    "                                misc_list.append(\"NestedTag=True\")\n",
    "                                #misc_list.append({\"NestedTag\":\"True\"})\n",
    "                                if \"_\\\\q_\" in word_form:\n",
    "                                    subtag = word_form.split(\"\\\\q\")[1].strip(\"_\")\n",
    "                                    misc_list.append(\"Quote='\"+subtag+\"'\")\n",
    "                                    #print (subtag)\n",
    "                                if \"_\\\\r_\" in word_form:\n",
    "                                    subtag = word_form.split(\"\\\\r\")[1].strip(\"_\")\n",
    "                                    misc_list.append(\"Repair='\"+subtag+\"'\")\n",
    "                                    #print (subtag)\n",
    "                                if \"_\\\\d_\" in word_form:\n",
    "                                    subtag = word_form.split(\"\\\\d\")[1].strip(\"_\")\n",
    "                                    misc_list.append(\"Disfluency='\"+subtag+\"'\")\n",
    "                                    #print (subtag)\n",
    "                                if \"_\\\\h_\" in word_form:\n",
    "                                    subtag = word_form.split(\"\\\\h\")[1].strip(\"_\")\n",
    "                                    misc_list.append(\"Hesitation='\"+subtag+\"'\")\n",
    "                                    #print (subtag)\n",
    "                                if \"_\\\\c_\" in word_form:\n",
    "                                    subtag = word_form.split(\"\\\\c\")[1].strip(\"_\")\n",
    "                                    misc_list.append(\"CodeSwitch='\"+subtag+\"'\")\n",
    "                                    #print (subtag)\n",
    "                                if \"_\\\\exp_\" in word_form:\n",
    "                                    subtag = word_form.split(\"\\\\exp\")[1].strip(\"_\")\n",
    "                                    misc_list.append(\"Expletive='\"+subtag+\"'\")\n",
    "                                    #print (subtag)   \n",
    "                                misc = r\"|\".join(misc_list) \n",
    "                                #print (type(misc))\n",
    "                                #print(misc_list)\n",
    "                                word_form = word_form.replace(\"\\\\q_\", \"\")\n",
    "                                word_form = word_form.replace(\"_\\\\q\", \"\")\n",
    "                                word_form = word_form.replace(\"\\\\r_\", \"\")\n",
    "                                word_form = word_form.replace(\"_\\\\r\", \"\")\n",
    "                                word_form = word_form.replace(\"\\\\d_\", \"\")\n",
    "                                word_form = word_form.replace(\"_\\\\d\", \"\")\n",
    "                                word_form = word_form.replace(\"\\\\h_\", \"\")\n",
    "                                word_form = word_form.replace(\"_\\\\h\", \"\")\n",
    "                                word_form = word_form.replace(\"\\\\c_\", \"\")\n",
    "                                word_form = word_form.replace(\"_\\\\c\", \"\")\n",
    "                                word_form = word_form.replace(\"\\\\exp_\", \"\")\n",
    "                                word_form = word_form.replace(\"_\\\\exp\", \"\")\n",
    "                                word_form = word_form.replace(\"__\", \"_\")\n",
    "\n",
    "                                result_list.append(word_n+'\\t'+word_form+'\\t'+\"_\"+'\\t'+\"_\"+'\\t'+\"_\"+'\\t'+\"_\"+'\\t'+\"_\"+'\\t'+\"_\"+'\\t'+\"_\"+'\\t'+misc+'\\n')\n",
    "                            else:\n",
    "                                word_form = word_form.replace(\"\\\\q_\", \"\")\n",
    "                                word_form = word_form.replace(\"_\\\\q\", \"\")\n",
    "                                word_form = word_form.replace(\"\\\\r_\", \"\")\n",
    "                                word_form = word_form.replace(\"_\\\\r\", \"\")\n",
    "                                word_form = word_form.replace(\"\\\\d_\", \"\")\n",
    "                                word_form = word_form.replace(\"_\\\\d\", \"\")\n",
    "                                word_form = word_form.replace(\"\\\\h_\", \"\")\n",
    "                                word_form = word_form.replace(\"_\\\\h\", \"\")\n",
    "                                word_form = word_form.replace(\"\\\\c_\", \"\")\n",
    "                                word_form = word_form.replace(\"_\\\\c\", \"\")\n",
    "                                word_form = word_form.replace(\"\\\\exp_\", \"\")\n",
    "                                word_form = word_form.replace(\"_\\\\exp\", \"\")\n",
    "                                word_form = word_form.replace(\"__\", \"_\")\n",
    "\n",
    "                                result_list.append(word_n+'\\t'+word_form+'\\t'+\"_\"+'\\t'+\"_\"+'\\t'+\"_\"+'\\t'+\"_\"+'\\t'+\"_\"+'\\t'+\"_\"+'\\t'+\"_\"+'\\t'+misc+'\\n')    \n",
    "                        else:\n",
    "                            result_list.append(word_n+'\\t'+word_form+'\\t'+\"_\"+'\\t'+\"_\"+'\\t'+\"_\"+'\\t'+\"_\"+'\\t'+\"_\"+'\\t'+\"_\"+'\\t'+\"_\"+'\\t'+\"_\"+'\\n')\n",
    "\n",
    "\n",
    "                with open(filename_out, 'w', encoding = 'utf-8') as f:\n",
    "                        for item in result_list:\n",
    "                            f.write(item)\n",
    "                        \n",
    "    def udpos(self):\n",
    "        \n",
    "        dirs = os.listdir(self.filepath)\n",
    "        #print(dirs)\n",
    "        for file in dirs:\n",
    "            filename = self.filepath+str(file)\n",
    "            \n",
    "            if filename.endswith(\"_ss_4misc.txt\"):\n",
    "                filename_in = filename\n",
    "                filename_out = filename_in.replace(\"_ss_4misc.txt\", \"_ss_5udpos.txt\")\n",
    "                #print (\"in = \"+ filename_in)\n",
    "                #print (\"out = \"+ filename_out)\n",
    "\n",
    "                with open(filename_in,'rb') as payload:\n",
    "                    #print(payload.read())\n",
    "                    #var=payload.read()\n",
    "                    #print(var)\n",
    "                    parameters = {\n",
    "                        \"data\": payload.read(),\n",
    "                        \"model\": \"hindi\",\n",
    "                        \"input\":\"conllu\",\n",
    "                        \"tagger\": 1,\n",
    "                    }\n",
    "\n",
    "                   #print(payload.read())\n",
    "\n",
    "                    response = requests.post(self.parser_url, parameters)\n",
    "                    #print(response)\n",
    "                    the_output = response.json()\n",
    "\n",
    "                    with open (filename_out, 'w', encoding= \"utf-8\") as file:\n",
    "                        file.write(the_output[\"result\"])\n",
    "                    \n",
    "        \n",
    "    def udpos_rules(self):\n",
    "        \n",
    "        dirs = os.listdir(self.filepath)\n",
    "        #print(dirs)\n",
    "        for file in dirs:\n",
    "            filename = self.filepath+str(file)\n",
    "            \n",
    "            if filename.endswith(\"_ss_5udpos.txt\"):\n",
    "                filename_in = filename\n",
    "                filename_out = filename_in.replace(\"_ss_5udpos.txt\", \"_ss_6udpos_rules.txt\")\n",
    "                #print (\"in = \"+ filename_in)\n",
    "                #print (\"out = \"+ filename_out)\n",
    "\n",
    "                file = pyconll.load_from_file(filename_in)\n",
    "\n",
    "                for sentence in file:\n",
    "                    for token in sentence:\n",
    "                        misc_item1 = list((token.misc).items())\n",
    "                        #print (misc_item1)\n",
    "                        tag = [('Quote', {'Matrix_Tag'}), ('Repair', {'Matrix_Tag'}), ('Disfluency', {'Matrix_Tag'}), \n",
    "                       ('Hesitation', {'Matrix_Tag'}),('CodeSwitch', {'Matrix_Tag'}), ('Expletive', {'Matrix_Tag'})]\n",
    "                        for i in tag:\n",
    "                            if i in misc_item1:\n",
    "                                token.upos =\"X\"\n",
    "                            #print(misc_item1)\n",
    "                            #print(token.upos)\n",
    "                        #help(token.misc)    \n",
    "                        \n",
    "                        if str(token.form) == \"[pause]\":\n",
    "                            token.upos = \"X\"\n",
    "                        \n",
    "                        if str(token.form) == \"[laughter]\":\n",
    "                            token.upos = \"X\"\n",
    "                            \n",
    "\n",
    "                        if str(token.form) == \"[incomprehensible]\":\n",
    "                            token.upos = \"X\"\n",
    "\n",
    "                        if str(token.form) == \"[noise]\":\n",
    "                            token.upos = \"X\"\n",
    "\n",
    "                        if str(token.form) == \"рд╣рд╛рдБ\":\n",
    "                            token.upos = \"PART\"        \n",
    "\n",
    "                        if str(token.form) == \"рд╣реНрдо\":\n",
    "                            token.upos = \"PART\" \n",
    "\n",
    "                        if str(token.form) == \"[anonymized]\":\n",
    "                            token.upos = \"PROPN\"\n",
    "\n",
    "                        if str(token.lemma) == \"рд╣реИ\" and str(token.xpos) == \"VM\":\n",
    "                            token.upos = \"VERB\"\n",
    "\n",
    "                        if str(token.lemma) == \"рдерд╛\" and str(token.xpos) == \"VM\":\n",
    "                            token.upos = \"VERB\"            \n",
    "\n",
    "                with open(filename_out, 'w', encoding = 'utf-8') as f:\n",
    "                    file.write(f)            \n",
    "\n",
    "                \n",
    "    def udpos_parse(self):\n",
    "        \n",
    "        dirs = os.listdir(self.filepath)\n",
    "        #print(dirs)\n",
    "        for file in dirs:\n",
    "            filename = self.filepath+str(file)\n",
    "            \n",
    "            if filename.endswith(\"_ss_6udpos_rules.txt\"):\n",
    "                filename_in = filename\n",
    "                filename_out = filename_in.replace(\"_ss_6udpos_rules.txt\", \"_ss_7udpos_parse.txt\")\n",
    "                #print (\"in = \"+ filename_in)\n",
    "                #print (\"out = \"+ filename_out)\n",
    "\n",
    "                with open(filename_in,'rb') as payload:\n",
    "                    parameters = {\n",
    "                        \"data\": payload.read(),\n",
    "                        \"model\": \"hindi\",\n",
    "                        \"input\":\"conllu\",\n",
    "                        \"parser\": 1,\n",
    "                    }\n",
    "\n",
    "                    response = requests.post(self.parser_url, parameters)\n",
    "                    the_output = response.json()\n",
    "\n",
    "                    with open (filename_out, 'w', encoding= \"utf-8\") as file:\n",
    "                        file.write(the_output[\"result\"])\n",
    "                        \n",
    "                        \n",
    "    \n",
    "    def parser_output(self):\n",
    "        \n",
    "        self.format1()\n",
    "        self.segment()\n",
    "        self.chunks()\n",
    "        self.misc()\n",
    "        self.udpos()\n",
    "        self.udpos_rules()\n",
    "        self.udpos_parse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e75499",
   "metadata": {
    "id": "75e75499"
   },
   "outputs": [],
   "source": [
    "path = \"E:/Cognitive_Science/Sem_III/HSD621_Masters_Project/syntactic_analysis/single_script/\"\n",
    "\n",
    "parser_url =  \"http://lindat.mff.cuni.cz/services/udpipe/api/process\"\n",
    "\n",
    "\n",
    "test1=Parser(path, parser_url)\n",
    "\n",
    "test1.parser_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4147a5b",
   "metadata": {
    "id": "d4147a5b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
